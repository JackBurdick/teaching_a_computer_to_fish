\chapter{Basics}

\section{Overview}

%%%%%%%%%%%%%%%%%%%%%%%% obligatory "No Free Lunch"
I'm not sure it's possible to discuss machine learning without at least mentioning the ``No Free Lunch'' theorem, which states ``No single classifier works best across all possible scenarios''

%%%%%%%%%%%%%%%%%%%%%%%% Types of data
\textcolor{blue}{categorical or numerical. Numerical can be discrete or continuous}

%%%%%%%%%%%%%%%%%%%%%%%% Measurement Levels
\textcolor{blue}{qualitative or quantitative.} 

\textcolor{blue}{Qualitative can be nominal (aren't numbers and can't be put in any order -- e.g. the seasons: spring, summer, fall, winter) or ordinal (groups and categories that follow a strict order -- e.g. difficult levels: hard, medium, or easy)}

\textcolor{blue}{Quantitative are represented by numbers but can be interval (0 is meaningless -- e.g. temperature in C or F, where true zero is not 0) or ratio (has a true 0 -- e.g. temperature in K, weight or length)}

\section{Workflow Overview / Blue Print}

% TODO: does not belong here
/r{feature extraction --> (manual or learned) ==> ``classification''}

% TODO: this will need to be checked+rechecked+redone
\textcolor{blue}{1. explore, 2. create datasets, 3. benchmark}
\begin{enumerate}
	\item Problem definition
	\item Hypothesis?
	\item explore data
	\item (shuffle? representative)
	\item remove split for testing
	\item prepare data
	\item split into train/val
	\item Choose measure of success
	\item Perform baseline -- what performance is expected/realistic goal expectations/ how does a simple, well tested, classifier work?
	\item Develop model
	\begin{enumerate}
		\item Can you (over)fit the training data? - more data?
		\item Fit the validation as best as possible (regularization, augmentation) (WARN: \textcolor{red}{local ref to information leak})
	\end{enumerate}
	\item OTHERS...
	\item Evaluate
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%% Bias
\input{./nested/basics/bias}


%%%%%%%%%%%%%%%%%%%%%%%% Acquiring Data
\input{./nested/basics/acquiring_data}

%%%%%%%%%%%%%%%%%%%%%%%% Data Pre-processing
\input{./nested/basics/data_preprocessing}

%%%%%%%%%%%%%%%%%%%%%%%% Data Type Considerations + Feature Extraction
\input{./nested/basics/data_type_considerations}


%%%%%%%%%%%%%%%%%%%%%%%% Data sampling and partitioning
\input{./nested/basics/sampling_partitioning}

\section{Some Terms}

\emph{input variable(s)} -- predictors, independent variables, features, regressors, controlled variables, exposure variables or simply variables.
 
\emph{output variable(s)} -- response or dependent variable. May also be known as regressands, criterion variables, measured variables, responding variables, explained variables, outcome variables, experimental variables, labels.

\textcolor{blue}{Both input and output variables may take on continuous or discrete values.}

\emph{relationship} $Y = f(x) + \epsilon$ \textcolor{blue}{estimate $f$. prediction and inference}.

\textcolor{blue}{\emph{{reducible error}\index{reducible error}} -- the estimated function $\hat{f}$ will likely not be perfect, and the reducible error is the error that could potentially be corrected (perhaps by using a more appropriate learning technique to estimate $\hat{f}$).  The \emph{irreducible error} is an error that can not be corrected. The irreducible error may be larger than zero due to either \emph{unmeasured variables} \emph{e.g.} variables that were not measured or \emph{unmeasurable variation} \emph{e.g.} an individual's feelings/emotions or variation in the production of a product, or both. The irreducible error provides an upper bound on the performance of the predicted $\hat{f}$}

\textcolor{red}{inference: relationship between predictors and response}

% TODO: not sure ~exactly where this fits yet..
\textcolor{blue}{parameters -- model variables that change during training. Hyper-parameters are set before training.}

\section{Type of Learning}

\textcolor{blue}{Three main types of machine learning: supervised, unsupervised, and reinforcement.}

% From ML for Predictive Data Analytics
\textcolor{blue}{Another way to group types of learning -- Information-based, similarity-based, probability-based, and error-based}

\subsection{Supervised}

\textcolor{blue}{observe input variables with corresponding output values. A program that predicts an output for an input by learning from pairs of labeled inputs and outputs. Classification \textcolor{red}{ref} and regression \textcolor{red}{ref} are subcategories of supervised learning}

\textcolor{blue}{Examples: OCR, Fraudulent banking transactions, medical images}

\subsection{Unsupervised}

\textcolor{blue}{observe input variables without corresponding output values and attempts to discover patterns in the data.}

% p14 of mastering ml agorithms
\textcolor{blue}{There is no error signal to measure, rather, performance metrics report some attribute of structure discovered in the data, such as the distances within and between clusters.}

\textcolor{blue}{Determining whether the method learned ``something'' useful is inherently difficult --- since, by definition, there are no labels. \textcolor{green}{TODO: example}.}


\textcolor{blue}{these methods are described in more detail in \textcolor{red}{local ref}}

\textcolor{blue}{Examples: segmenting customers...}
 
% clustering
\subsubsection{Clustering}

\textcolor{blue}{Finding sub groups where observations are more similar to eachother based on some similarity measure. Clustering is sometimes referred to as ``unsupervised classification'' and is often used to explore a dataset.}

\textcolor{blue}{An example of clustering may be to group a collection of documents into categories, or songs into genres.}

% principal components
\subsubsection{Unsupervised Transformations}

\textcolor{blue}{Dimensionality Reduction --- where the goal is to reduce the dimensionality of the data while retaining as much as the relevant information as possible}

%% topic extraction

\textcolor{blue}{A high number of features may be computationally costly. Ability to generalize may be reduced if some of the features capture noise or are irrelevant to the underlying relationship. The goal could be to find the features that account for the greatest changes in the response variable}


\subsection{Semi-supervised Learning}

\textcolor{blue}{`semi-supervised learning', another type of learning, makes use of both supervised and unsupervised data.}

\subsection{Reinforcement}

\r{Reinforcement learning does not learn from labeled pairs of inputs and outputs, rather it learns from `feedback' from decisions that are not explicitly corrected. Information is still supplied to the system as to whether the networks outputs are good or bad, but no actual desired values are given.}

\textcolor{blue}{Goal -- develop an \emph{agent} that improves it's performance based on interactions with an \emph{environment} based on a \emph{reward}}

\subsection{Supervised vs Unsupervised}

\subsection{Classification vs Regression}

\subsubsection{Regression} 

Regression, also called regression analysis \textcolor{red}{local ref?} involves predicting a continuous or quantitative output value. For example attempting to find a relationship between a given predictor/explanatory variables (age, job title, zip code) and a continuous response (an individuals outcome).

\subsubsection{Classification} 

Classification involves predicting categorical (discrete) or qualitative output value (such as a non-numerical value). 

\textcolor{blue}{Binary classification (benign vs malignant) and multi-class classification (identifying many different skin diseases).}

\subsection{Multi-label classification}
\textcolor{blue}{TODO: {multi-label classification}\index{multi-label classification} --- where a classifier assigns multiple labels to each instance}

% TODO: placement
\textcolor{blue}{Evaluating every output node for every example can quickly become computationally expensive. approximate version of softmax. i) candidate sampling (tf.nn.sampled\_softmax\_loss()) \textcolor{red}{calculates the output for all of the positive labels, but will only calculate the label for a random sample of negatives. Where the number of negatives sampled is a a hyperparameter} ii) noise-contrastive estimation (tf.nn.nce\_loss()) \textcolor{red}{approximates the denominator of softmax by modeling the distribution of outputs}. Typically, these two methods may be used during training, but the full softmax function will be used during inference.}


\subsubsection{Approaches: Problem transformation}

\textcolor{blue}{There are two main approaches to multi-label classification}

\textcolor{blue}{{Problem transformation}\index{Problem transformation} modify the original multi-label problem to a set of single-label classification problems.}

\paragraph{Unique set/combination of labels}

\textcolor{green}{TODO: table and example.}

\textcolor{blue}{Two main concerns with this methodology: i) increasing the number of classes is impractical and will often have very few instances and ii) the classifier can only predict combinations that were seen in the training data.}

\paragraph{Many Binary Classifiers}

% p124[112] of Mastering ML with SKL
\textcolor{blue}{Train a classifier for each label in the training set. The final prediction is the combination of all the predictions from the binary classifiers.}

\textcolor{blue}{The main concern with this approach is that the relationships between labels is ignored.}

\subsubsection{Evaluating Multi-label Classification}

\textcolor{blue}{see \textcolor{red}{local ref}.}

% page 94 of AGtext
One-versus-all \emph{OvA} (also \emph{one-versus-rest}) -- $n$, separate binary classification problems, where the $n$ is the number of classes. The target class may be assigned as the positive class and `all' the `rest' of the classes may be assigned as the negative class.

One-versus-one (OvO) -- train a binary classifier for every pair


\textcolor{blue}{Binary classification can be extended to multi-class classification via the OvR method.}

%\subsubsection{Bayes Classifier}

\section{Training}

\subsection{Cost, Loss Function}

\textcolor{red}{Cost and Loss functions -- I'm not sure why I didn't have this yet?}

\textcolor{blue}{A loss function is responsible for providing a measure of performance for the training data -- thus the loss function is responsible for guiding the training process.}

\textcolor{blue}{\textit{objective function}}

\textcolor{red}{example of plots - step by step}

\textcolor{red}{contour maps}

\textcolor{blue}{it is possible that a DNN graph may have multiple loss functions (where each one is responsible for a specific output class). Since the gradient descent process relies on a single scalar loss value, graphs with multiple losses will combine these losses (\textcolor{red}{via averaging})}

\textcolor{blue}{TODO: general loss plot example/figure}

\textcolor{blue}{TODO: section (maybe in another location) that shows how to "troubleshoot" a loss plot. So examples of what a noisy loss plot vs a flat loss plot might indicate. Would also be nice to expand to include examples of the loss plot of the training and validation (likely another section, but with a reference in this section pointing to it.)}

\textcolor{blue}{TODO: talk about "convexity" -- show 3D loss plot (2D for params, 3rd for loss), and explain how running/re-running a model may result in slightly different values.}

\textcolor{blue}{Loss calculation. TODO: example for linear linear regression and why sum of loss will cancel out terms. \textcolor{red}{point to local ref.}}

\subsection{Error Functions}

\r{discussion of techniques used for training networks}

\r{the training of a network consists of a suitable error function to be minimized with respect to teh parameters (weights and biases) of a network.}

\subsubsection{Least-squares techniques}

\r{simple error function, typically most suitable for regression problems, but could also be used for classificaiton problems, though other error functions typcially perform better for classification (\textcolor{red}{local ref})}

\paragraph{Sum-of-squares error function}

\paragraph{Normal Equations}

\r{find an explicity solution to the function}

\paragraph{Singular Value Decomposition (SVD)}

\r{Singular Value Decomposition (SVD) --- technique used to help solve problems like ``near degeneracies'' (\textcolor{green}{TODO: unsure of this --- also see Press et al. 1992 for an introduction})}


\paragraph{Gradient Descent}

\r{\textcolor{green}{TODO: is this the first time I've talked about this?}. Finding the weight values of a sum-of-squares error function can be found explicityly in terms of the \TD{pseudo inverse of a matrix} (if a linear network). However, if a non-liear activation fuction is used, then the closed form of a solution is no longer possible.}

\r{If a derivative of the activation function is differentiable, the derivatives of the error function with respect to the weight parameters can then be evaluated. The derivatives can then be used by gradient-based optimization algorithms to find the minimum of the error function \TD{local ref - sec on optimizers}}

\r{update the parameters one iteration at a time --- sequential, pattern-based, update}


\subsubsection{Global vs Local Minima}

% TODO: this needs to be placed elsewhere
\textcolor{blue}{show how a simple problem may get "stuck" in a local mimima (plot decision boundary for 2D feature space) and show how it changes with different initialization (use different random seeds). }

\textcolor{blue}{{inappropriate minima}\index{inappropriate minima} -- don't reflect the relationship between features and output and/or don't generalize well.}

\section{Quality of Fit}

%% regression example

\subsection{Regression Example}

% TODO: need to think about placement of these and how to organize the general case.

\textcolor{blue}{squared will handle the issue with positive and negative error terms canceling each other out as well as penalizing terms more when they are larger}

\textcolor{blue}{Mean Squared Error.$\hat{f}(x_i)$ is the prediction that $\hat{f}$ produces for the $i$th sample (\ref{eq:MSE_def}). The output will be small for predicted values that are similar to the ground truth}

\begin{equation}
{MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2}
\label{eq:MSE_def}
\end{equation}

\textcolor{blue}{The MSE may be hard to interpret since the error is squared. \textcolor{red}{example}}

\textcolor{blue}{Root mean squared error, which is simply the root of the MSE. (\ref{eq:RMSE_def})}

\begin{equation}
{RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2}}
\label{eq:RMSE_def}
\end{equation}

\textcolor{blue}{"problem" with this loss function is that it does not follow the intuition that really bad predictions should be penalized more harshly than predictions that are just "a little bad"}

% TODO: again, need to devise a better way to organize this section (loss functions)
\textcolor{red}{Cross entropy or log loss. \textcolor{red}{CITE} (related to Shannon's information theory \textcolor{red}{CITE})}


%% classification example

\subsection{Classification Example}

\textcolor{blue}{The proportion of mistakes that are made.}

\begin{equation}
{error\_rate = \frac{1}{n}\sum_{i=1}^{n}(y_i \ne \hat{y_i})}
\label{eq:class_error_rate_def}
\end{equation}

\textcolor{blue}{$\hat{y_i}$ is the predicted classification label for the $i$th observation using our predictor/model $\hat{f}$ and $y_i$ is the ground truth label}

\section{Describing Learners}

\subsection{Parametric and non-parametric}

\subsubsection{parametric}

\rr{parametric models are models that learn a fixed number of parameters that are able to classify new data points without requiring the original dataset anymore. First, a function form is selected (linear, polynomial, etc.), then the coefficients for the function are learned from the training data.}

\textcolor{green}{TODO: example \r{predicting the income of an individual $income \approx \beta_0 + \beta_1 \times education_{yrs} + \beta_2 \times experience_{yrs}$ --- assuming a linear relationship between response and two predictors}}

\textcolor{green}{TODO: plot of example -- }

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.5\textwidth]{example-image-a}\hfil
	\caption{Figure example of assumed linear model and datapoints \textcolor{green}{TODO}}
	\label{fig:basics_para_assume_linear}
\end{figure}



\textcolor{blue}{Examples of parametric models may be simple artificial neural networks, naive bayes, logistic regression, etc.}

\subsubsection{nonparametric}

%% unsure about this! 
\textcolor{red}{Nonparametric models are not models without parameters, rather they are models were the number of parameters are not fixed, they may grow with the number of training instances}

\textcolor{blue}{May be useful when little is known about the underlying relationship in the data and there is an abundance of data.}

\textcolor{blue}{An Example of a nonparametric model may be k-Nearest neighbors -- where the model does not assume anything about the form of the mapping function and makes predictions based on the k most similar training instances.}

\subsubsection{parametric vs nonparametric}

\r{An advantage of a nonparametric approach may be that the model does not make any explicit assumptions about the best fitting model thus avoiding limiting the model to a functional form $f$ that may not be similar to the true $f$ --- for example, using a linear model for a model that is cleary \textcolor{red}{parametric} in form. Typically, since a nonparametric approach is not limited to an explicit number of parameters, a larger amount of data is required to obtain an accurate estimate of $f$.}

\textcolor{blue}{A disadvantage to this type of approach is that the computational complexity for classifying new samples grow linearly with the number of samples in the training set.}



\subsection{Eager vs Lazy Learners}

\textcolor{green}{TODO: Eager vs Lazy overview}
\textcolor{blue}{Training an eager learner is often more computationally expensive, but typically prediction with the resulting model is inexpensive.}

\subsubsection{Eager Learners}

\textcolor{blue}{Eager learners estimate the parameters of a model that generalize to a training set --- build an input-independent model}

\subsubsection{Lazy Learners}

\textcolor{blue}{Also known as Instance-based Learners}

\textcolor{blue}{do not spend time training, but may predict responses slowly (relatively) compared to eager learners}

\textcolor{blue}{Lazy learners store the training dataset with little to no processing.}


\subsection{Generative vs Discriminative Models}

\textcolor{green}{TODO: Generative vs Discriminative models overview}
%\textcolor{blue}{}

\subsubsection{Discriminative Models}

\textcolor{green}{TODO: Discriminative Models --- learn a decision boundary that is used to \textit{discriminate} between classes. There exist both probabilistic and non-probabilistic discriminative models}

\paragraph{Probabilistic Discriminative}

\textcolor{blue}{Probabilistic discriminative models learn to estimate the conditional probability i.e. which class is most probable given the input features.}

\paragraph{Non-probabilistic Discriminative}

\textcolor{blue}{Non-probabilistic discriminative models directly map features to classes.}

\subsubsection{Generative Models}

% see p129[117] of Mastering ML w/SKL
\textcolor{green}{TODO: Generative Models --- do not learn a decision boundary, rather, they model the joint probability distribution of the features and classes i.e. they model how the classes generate features. Then, using Bayes' theorem, they are able to estimate the conditional probability of a class given the features.}


% see p130[118] of Mastering ML w/SKL
\textcolor{blue}{One advantage of generative models is that they can be used to generate new examples of data}

\subsection{Strong vs Weak Learners}

\textcolor{green}{TODO: Strong vs Weak learners (classifier, predictor, etc.) overview}
%\textcolor{blue}{}

\subsubsection{Strong Learners}

\textcolor{green}{TODO: Strong Learners are models that are arbitrarily better than weak learners.}

\subsubsection{Weak Learners}

\textcolor{green}{TODO: Weak Learners are models (typically simple models) that perform only slightly better than random chance.} \textcolor{blue}{typically used in ensemble methods --- TODO: overview - discussed in more detail in \textcolor{red}{local ref?}}


\section{Online Learning}

% See p.246 of Understanding Machine learning
\textcolor{blue}{difference to \textcolor{red}{PAC learning?}}



\section{Kernel Methods}
\label{sec:kernel_trick}

\textcolor{blue}{Adding non-linear features to data in attempt linearly separate the data.}

 %Adding non-linear features is a powerful method for allowing linear methods to separate non-linear data. However, which features, combinations of features, and types of features is often not easily known. And adding may of these features may become computationally limiting

\textcolor{blue}{Transform the training data onto a higher dimensional feature space}

% see p177[165] of mastering ML with SKL

\textcolor{blue}{The kernel is a function that XXXXXXXXXX}

\textcolor{blue}{Choosing an appropriate kernel can be challenging}

% computing the distance (scalar products) of data points for the expanded feature representation --- but doesn't compute the expansion

% see p180[168] of mastering ML w/SKL for more on kernels
\textcolor{blue}{Some commonly used kernels include polynomial, RBF, sigmoid, Guassian, and linear kernels}

\textcolor{blue}{commonly used in SVMs (see \textcolor{red}{local ref}), the kernel trick can be used with any model that can be expressed in terms of the dot product of two feature vectors.}

\textcolor{blue}{the mapping function is not fully computed due to the kernel trick}

\subsection{Kernel Trick}

\subsection{Kernels}

\textcolor{blue}{There are many kernel functions. Choosing the ``best'' kernel will depend on the current problem.}

\textcolor{red}{kernel functions are continuous and symmetric}

\textcolor{red}{TODO: put these into context and/or give an example}

\textcolor{blue}{the word kernels is representative of a weighting function \textcolor{red}{or weighted sum or integral}}


% https://data-flair.training/blogs/svm-kernel-functions/
% http://crsouza.com/2010/03/17/kernel-functions-for-machine-learning-applications/

\textcolor{red}{TODO: automatic kernel selection}

\subsubsection{Polynomial}

\textcolor{blue}{polynomial computes all possible polynomials of the original features up to a certain degree}

\textcolor{blue}{parameters: slope ($\alpha$), constant $c$, polynomial degree $d$}
\begin{equation}
{k(x, y) = (\alpha x^T y + c)^d}
\label{eq:kernel_polynomial_eq}
\end{equation}
% TODO: double check

\subsubsection{Gaussian / RBF (Radial Basis Function)}

\textcolor{blue}{circles/hypersphere}
\textcolor{red}{infinite-dimensional feature space}

\begin{equation}
{k(x, y) = exp(- \gamma || x_1 - x_2 || ^2 ) }
\label{eq:kernel_guassian_rbf_eq}
\end{equation}

\textcolor{blue}{$|| x_1 - x_2 ||$ represents the euclidean distance and $\gamma$ represents the parameter that controls the width of the Gaussian kernel (the inverse width of the Gaussian kernel). $\gamma$ controls how far the influence of a single training instance reaches --- high values correspond to a limited reach (typically result in lower complexity) and low values correspond to a far reach (typically result in higher complexity).}

\textcolor{green}{Would be nice to have a figure with low - medium - high values for the hyperparameters and the outcome}


\subsection{Less Common Kernels}



%\subsubsection{Laplace RBF}

%\subsubsection{Hyperbolic Tangent}

%\subsubsection{ANOVA Radial Basis Kernel}

%\subsubsection{Sigmoid}

%%%%%%%%%%%%%%%%%%% Hyper-parameters
\input{./nested/basics/hyperparams}

%%%%%%%%%%%%%%%%%%%%%%%% Optimizers

\section{Estimating Model Parameters}

\textcolor{green}{Iterative Estimation vs Calculation}

% http://mathworld.wolfram.com/NormalEquation.html
% https://eli.thegreenplace.net/2014/derivation-of-the-normal-equation-for-linear-regression
\textcolor{green}{TODO: Normal Equation}

% TODO: non-invertable (singular or degenerate) matrix

% common causes (not verified) - 1) redundant features 2) too many features - more features than samples. solutions may be to delete features

\input{./nested/basics/initialization}

\input{./nested/basics/optimizers}

%%%%%%%%%%%%%%%%%%%%%%%% Evaluation
\input{./nested/basics/evaluation}

%%%%%%%%%%% Metrics (subsec nested under sec.Eval)
\input{./nested/basics/metrics}

%%%%%%%%%%%%%%%%%%%%%%%% Regularization
\input{./nested/basics/regularization}


%%%%%%%%%%%%%%%%%%%%%%%% Distributed
\input{./nested/basics/distributed}

