\chapter{Basics}

\section{Overview}

%%%%%%%%%%%%%%%%%%%%%%%% obligatory "No Free Lunch"
% TODO: there is more to the no free lunch than simply this.
\r{I'm not sure it's possible to discuss machine learning without at least mentioning the ``No Free Lunch'' theorem, which states ``No single classifier works best across all possible scenarios''~\cite{wolpert1997no}}

% “You can’t learn from data without making assumptions”
\TD{A Lot to unpack here.}
\TD{https://peekaboo-vision.blogspot.com/2019/07/dont-cite-no-free-lunch-theorem.html}

%%%%%%%%%%%%%%%%%%%%%%%% Types of data
\r{categorical or numerical. Numerical can be discrete or continuous}

%%%%%%%%%%%%%%%%%%%%%%%% Measurement Levels
\r{qualitative or quantitative.} 

\r{Qualitative can be nominal (aren't numbers and can't be put in any order -- e.g. the seasons: spring, summer, fall, winter) or ordinal (groups and categories that follow a strict order -- e.g. difficult levels: hard, medium, or easy)}

\r{Quantitative are represented by numbers but can be interval (0 is meaningless -- e.g. temperature in C or F, where true zero is not 0) or ratio (has a true 0 -- e.g. temperature in K, weight or length)}

\section{Workflow Overview / Blue Print}

% TODO: does not belong here
\r{feature extraction -- (manual or learned) == ``classification''}

% TODO: this will need to be checked+rechecked+redone
\r{1. explore, 2. create datasets, 3. benchmark}
\begin{enumerate}[noitemsep,topsep=0pt]
	\item Problem definition
	\item Hypothesis?
	\item explore data
	\item (shuffle? representative)
	\item remove split for testing
	\item prepare data
	\item split into train/val
	\item Choose measure of success
	\item Perform baseline -- what performance is expected/realistic goal expectations/ how does a simple, well tested, classifier work?
	\item Develop model
	\begin{enumerate}[noitemsep,topsep=0pt]
		\item Can you (over)fit the training data? - more data?
		\item Fit the validation as best as possible (regularization, augmentation) (WARN: \textcolor{red}{local ref to information leak})
	\end{enumerate}
	\item OTHERS...
	\item Evaluate
\end{enumerate}


\section{Some Terms}

\emph{input variable(s)} -- predictors, independent variables, features, regressors, controlled variables, exposure variables or simply variables.
 
\emph{output variable(s)} -- response or dependent variable. May also be known as regressands, criterion variables, measured variables, responding variables, explained variables, outcome variables, experimental variables, labels.

\textcolor{blue}{Both input and output variables may take on continuous or discrete values.}

\emph{relationship} $Y = f(x) + \epsilon$ \textcolor{blue}{estimate $f$. prediction and inference}.

\textcolor{blue}{\emph{{reducible error}\index{reducible error}} -- the estimated function $\hat{f}$ will likely not be perfect, and the reducible error is the error that could potentially be corrected (perhaps by using a more appropriate learning technique to estimate $\hat{f}$).  The \emph{irreducible error} is an error that can not be corrected. The irreducible error may be larger than zero due to either \emph{unmeasured variables} \emph{e.g.} variables that were not measured or \emph{unmeasurable variation} \emph{e.g.} an individual's feelings/emotions or variation in the production of a product, or both. The irreducible error provides an upper bound on the performance of the predicted $\hat{f}$}

\textcolor{red}{inference: relationship between predictors and response}

% TODO: not sure ~exactly where this fits yet..
\textcolor{blue}{parameters -- model variables that change during training. Hyper-parameters are set before training.}

\section{Type of Learning}

%That is, there are more exciting areas of coverstaion than getting hung up on the categorizations of these types of ``learning''. 
% TODO: link FB blog post
\r{Typically, three main types of machine learning are described: supervised, unsupervised, and reinforcement. However, there exist other subareas (e.g. semi-supervised learning, self-supervised learning, \TD{more}), and then within/across these divisions, there are further subdivisions that exist (e.g. contrastive learning, ciriculum learning, \TD{more}). And in reality, these lines are explicit or exact. One example has recently become popular is the definition of ``unsupervised learning'' and how the name is a bit of a miscategorization in that there are often many more training signals (labels, though not called labels) when using this paradigm than say in an binary image classifier in which there is a single label assignment per input (e.g. cat vs dog.)}

% From ML for Predictive Data Analytics
\textcolor{blue}{Another way to group types of learning -- Information-based, similarity-based, probability-based, and error-based}

% TODO: did I come up with these definitions or find them somewhere? - 18July21
\r{however, in the intrest of consistency, the typcial definitions are defined below.}
\begin{itemize}[noitemsep,topsep=0pt]
	\item Supervised Learning (\ALR)
	\begin{itemize}[noitemsep,topsep=0pt]
		\item \r{observe input variables with corresponding output values. A program that predicts an output for an input by learning from pairs of labeled inputs and outputs. Classification \ALR and regression \ALR are subcategories of supervised learning}
	\end{itemize}
	\item Unsupervised (\ALR)
	\begin{itemize}[noitemsep,topsep=0pt]
		\item \r{observe input variables without corresponding output values and attempts to discover patterns in the data. There is no error signal to measure, rather, performance metrics report some attribute of structure discovered in the data, such as the distances within and between clusters. Determining whether the method learned ``something'' useful is inherently difficult --- since, by definition, there are no labels.}
	\end{itemize}
	\item{Reinforcement (\ALR)}
	\begin{itemize}[noitemsep,topsep=0pt]
		\item \r{Reinforcement learning does not learn from labeled pairs of inputs and outputs, rather it learns from `feedback' from decisions that are not explicitly corrected. Information is still supplied to the system as to whether the networks outputs are good or bad, but no actual desired values are given. Goal -- develop an \emph{agent} that improves it's performance based on interactions with an \emph{environment} based on a \emph{reward}}
	\end{itemize}
\end{itemize}


\subsection{Supervised vs Unsupervised}

\subsection{Classification vs Regression}

\subsubsection{Regression} 

\r{Regression, also called regression analysis \textcolor{red}{local ref?} involves predicting a continuous or quantitative output value. For example attempting to find a relationship between a given features/predictor/explanatory variables (\textit{e.g.} age, job title, zip code) and a continuous response (\textit{e.g.} an individuals outcome).}

\subsubsection{Classification} 

Classification involves predicting categorical (discrete) or qualitative output value (such as a non-numerical value). 

\r{Binary classification (\textit{e.g.} dog vs cat, true vs false) and multi-class classification (\textit{e.g.} identifying many different skin diseases).}

\subsection{Multi-class}

% TODO:
\begin{itemize}[noitemsep,topsep=0pt]
	\item \TD{macro averaged: all classes independently, averaged}
	\item \TD{micro averaged:}
	\item \TD{weighted: macro, weighted by sample frequency}
\end{itemize}


\subsection{Multi-label}
\TD{TODO: {multi-label classification}\index{multi-label classification} --- where a classifier assigns multiple labels to each instance}


% TODO: placement
\textcolor{blue}{Evaluating every output node for every example can quickly become computationally expensive. approximate version of softmax. i) candidate sampling (tf.nn.sampled\_softmax\_loss()) \textcolor{red}{calculates the output for all of the positive labels, but will only calculate the label for a random sample of negatives. Where the number of negatives sampled is a a hyperparameter} ii) noise-contrastive estimation (tf.nn.nce\_loss()) \textcolor{red}{approximates the denominator of softmax by modeling the distribution of outputs}. Typically, these two methods may be used during training, but the full softmax function will be used during inference.}


\subsubsection{Approaches: Problem transformation}

\textcolor{blue}{There are two main approaches to multi-label classification}

\textcolor{blue}{{Problem transformation}\index{Problem transformation} modify the original multi-label problem to a set of single-label classification problems.}

\paragraph{Unique set/combination of labels}

\textcolor{green}{TODO: table and example.}

\textcolor{blue}{Two main concerns with this methodology: i) increasing the number of classes is impractical and will often have very few instances and ii) the classifier can only predict combinations that were seen in the training data.}

\paragraph{Many Binary Classifiers}

% p124[112] of Mastering ML with SKL
\textcolor{blue}{Train a classifier for each label in the training set. The final prediction is the combination of all the predictions from the binary classifiers.}

\textcolor{blue}{The main concern with this approach is that the relationships between labels is ignored.}

\subsubsection{Evaluating Multi-label Classification}

\textcolor{blue}{see \textcolor{red}{local ref}.}

% page 94 of AGtext
\r{One-versus-all \emph{OvA} (also \emph{one-versus-rest}) -- $n$, separate binary classification problems, where the $n$ is the number of classes. The target class may be assigned as the positive class and `all' the `rest' of the classes may be assigned as the negative class.
}
\r{One-versus-one (OvO) -- train a binary classifier for every pair}


\textcolor{blue}{Binary classification can be extended to multi-class classification via the OvR method.}

%\subsubsection{Bayes Classifier}

\section{Training}

\TD{Difference between the loss and metric functions}

\r{Metrics are what we care about and how we, as humans, measure the performance.}

\r{Loss is a proxy for the metric}

\TD{distinction: losses are differentiable, metrics are not \TD{show the importance of this somewhere}}

\subsection{Performance}

\subsubsection{Cost, Loss Function}

\textcolor{red}{Cost and Loss functions -- I'm not sure why I didn't have this yet?}

\textcolor{blue}{A loss function is responsible for providing a measure of performance for the training data -- thus the loss function is responsible for guiding the training process.}

\textcolor{blue}{\textit{objective function}}

\textcolor{red}{example of plots - step by step}

\textcolor{red}{contour maps}

\textcolor{blue}{it is possible that a DNN graph may have multiple loss functions (where each one is responsible for a specific output class). Since the gradient descent process relies on a single scalar loss value, graphs with multiple losses will combine these losses (\textcolor{red}{via averaging})}

\textcolor{blue}{TODO: general loss plot example/figure}

\textcolor{blue}{TODO: section (maybe in another location) that shows how to "troubleshoot" a loss plot. So examples of what a noisy loss plot vs a flat loss plot might indicate. Would also be nice to expand to include examples of the loss plot of the training and validation (likely another section, but with a reference in this section pointing to it.)}

\textcolor{blue}{TODO: talk about "convexity" -- show 3D loss plot (2D for params, 3rd for loss), and explain how running/re-running a model may result in slightly different values.}

\textcolor{blue}{Loss calculation. TODO: example for linear linear regression and why sum of loss will cancel out terms. \textcolor{red}{point to local ref.}}

\r{``surrogate loss'' --- takes a classification problem and turns it to a continuous/smooth surface.}


\subsubsection{Metrics}

\subsection{Error Functions}

\TD{discussion of techniques used for training networks}

\r{the training of a network consists of a suitable error function to be minimized with respect to the parameters (weights and biases) of a network.}



\subsubsection{forward pass}

\subsubsection{backward pass}

\subsubsection{Least-squares techniques}

\r{simple error function, typically most suitable for regression problems, but could also be used for classificaiton problems, though other error functions typcially perform better for classification (\textcolor{red}{local ref})}

\paragraph{Sum-of-squares error function}

\r{potential negative --- the largest contributions are from points with the largest error. If the dataset contains many outliers (or if the distribution contains long tails), the the adjustments can be dominated by these outliers. NOTE: in this case especially, it is essential to ensure there are no mislabeled data, as these can have dramatic effects. Techniques used to address this problem are known as robust statistics \TD{local ref -- create subsec for this == \textcolor{red}{see (Huber 1981)}}}

% see p.211 of NN by bishop (p.226 on tablet)
\textcolor{red}{input-dependent variance}

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.4\textwidth]{example-image-a}\hfil
	\includegraphics[width=0.4\textwidth]{example-image-b}\hfil
	\caption{ \TD{figure of how a model is affected by outliers. left: the data does not have any outliers and a linear line fits the data fairly well. right: a single outlier dramatically alters the linear line}}
	\label{fig:basics_error_fn_sumofsquares_outlier}
\end{figure}

\r{can be used for regression or classification (though typically for regression)}

 
\paragraph{Normal Equations}

\r{find an explicity solution to the function}

\paragraph{Singular Value Decomposition (SVD)}
% TODO: read: https://twitter.com/WomenInStat/status/1285610321747611653

\r{Singular Value Decomposition (SVD) --- technique used to help solve problems like ``near degeneracies'' (\textcolor{green}{TODO: unsure of this --- also see Press et al. 1992 for an introduction})}


\paragraph{Gradient Descent}

\r{repeatedly choosing and moving toward a descent direction until convergence} \TD{local descent may be another name}. \TD{there are many schemes for choosing the size of the step, discussed further in \ALR.}

%\r{\textcolor{green}{TODO: is this the first time I've talked about this?}. Finding the weight values of a sum-of-squares error function can be found explicitly in terms of the \TD{pseudo inverse of a matrix} (if a linear network).}
% However, if a non-linear activation fuction is used, then the closed form of a solution is no longer possible ? % what is the source for this?

\r{If a derivative of the activation function is differentiable, the derivatives of the error function with respect to the weight parameters can then be evaluated. The derivatives can then be used by gradient-based optimization algorithms to find the minimum of the error function \TD{local ref - sec on optimizers}}

\r{update the parameters one iteration at a time --- sequential, pattern-based, update}


\subsubsection{Global vs Local Minima}

\ALR to calculus section

% TODO: this needs to be placed elsewhere
\textcolor{blue}{show how a simple problem may get "stuck" in a local mimima (plot decision boundary for 2D feature space) and show how it changes with different initialization (use different random seeds). }

\textcolor{blue}{{inappropriate minima}\index{inappropriate minima} -- don't reflect the relationship between features and output and/or don't generalize well.}

\r{a local minimum will have a zero derivative, as it is not possible for a nonzero derivative to be a mimima.  However, just because a point has a nonzero derivative, it does not mean that it is a minima, it could also be local maxima or an inflection point. A positive second derivative would indicate that the point is a local minima.}

\section{Quality of Fit}

%% regression example

\subsection{Regression Example}

% TODO: need to think about placement of these and how to organize the general case.

\textcolor{blue}{squared will handle the issue with positive and negative error terms canceling each other out as well as penalizing terms more when they are larger}

\textcolor{blue}{Mean Squared Error.$\hat{f}(x_i)$ is the prediction that $\hat{f}$ produces for the $i$th sample (\ref{eq:MSE_def}). The output will be small for predicted values that are similar to the ground truth}

\begin{equation}
{MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2}
\label{eq:MSE_def}
\end{equation}

\r{The MSE may be hard to interpret since the error is squared. \textcolor{red}{example}}

\r{Root mean squared error, which is simply the root of the MSE. (\ref{eq:RMSE_def})}

\begin{equation}
{RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2}}
\label{eq:RMSE_def}
\end{equation}

\textcolor{blue}{"problem" with this loss function is that it does not follow the intuition that really bad predictions should be penalized more harshly than predictions that are just "a little bad"}

% TODO: again, need to devise a better way to organize this section (loss functions)
\textcolor{red}{Cross entropy or log loss. \textcolor{red}{CITE} (related to Shannon's information theory \textcolor{red}{CITE})}

% TODO, include in losses?: penealize highly confident, highly incorrect
\TD{Log loss: def + interpretation}


%% classification example

\subsection{Classification Example}

\textcolor{blue}{The proportion of mistakes that are made.}

\begin{equation}
{error\_rate = \frac{1}{n}\sum_{i=1}^{n}(y_i \ne \hat{y_i})}
\label{eq:class_error_rate_def}
\end{equation}

\textcolor{blue}{$\hat{y_i}$ is the predicted classification label for the $i$th observation using our predictor/model $\hat{f}$ and $y_i$ is the ground truth label}

\section{Describing Learners}

\subsection{Parametric and non-parametric}

\subsubsection{parametric}

\rr{parametric models are models that learn a fixed number of parameters that are able to classify new data points without requiring the original dataset anymore. First, a function form is selected (linear, polynomial, etc.), then the coefficients for the function are learned from the training data.}

\textcolor{green}{TODO: example \r{predicting the income of an individual $income \approx \beta_0 + \beta_1 \times education_{yrs} + \beta_2 \times experience_{yrs}$ --- assuming a linear relationship between response and two predictors}}

\textcolor{green}{TODO: plot of example -- }

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.5\textwidth]{example-image-a}\hfil
	\caption{Figure example of assumed linear model and datapoints \textcolor{green}{TODO}}
	\label{fig:basics_para_assume_linear}
\end{figure}



\textcolor{blue}{Examples of parametric models may be simple artificial neural networks, naive bayes, logistic regression, etc.}

\subsubsection{nonparametric}

%% unsure about this! 
\textcolor{red}{Nonparametric models are not models without parameters, rather they are models were the number of parameters are not fixed, they may grow with the number of training instances}

\textcolor{blue}{May be useful when little is known about the underlying relationship in the data and there is an abundance of data.}

\textcolor{blue}{An Example of a nonparametric model may be k-Nearest neighbors -- where the model does not assume anything about the form of the mapping function and makes predictions based on the k most similar training instances.}

\subsubsection{parametric vs nonparametric}

\r{An advantage of a nonparametric approach may be that the model does not make any explicit assumptions about the best fitting model thus avoiding limiting the model to a functional form $f$ that may not be similar to the true $f$ --- for example, using a linear model for a model that is cleary \textcolor{red}{parametric} in form. Typically, since a nonparametric approach is not limited to an explicit number of parameters, a larger amount of data is required to obtain an accurate estimate of $f$.}

\textcolor{blue}{A disadvantage to this type of approach is that the computational complexity for classifying new samples grow linearly with the number of samples in the training set.}



\subsection{Eager vs Lazy Learners}

\textcolor{green}{TODO: Eager vs Lazy overview}
\textcolor{blue}{Training an eager learner is often more computationally expensive, but typically prediction with the resulting model is inexpensive.}

\subsubsection{Eager Learners}

\textcolor{blue}{Eager learners estimate the parameters of a model that generalize to a training set --- build an input-independent model}

\subsubsection{Lazy Learners}

\r{Also known as Instance-based Learners}

\r{do not spend time training, but may predict responses slowly (relatively) compared to eager learners}

\r{Lazy learners store the training dataset with little to no processing.}


\subsection{Generative vs Discriminative Models}

\TD{TODO: Generative vs Discriminative models overview}


\subsubsection{Discriminative Models}

\r{learn a decision boundary that is used to \textit{discriminate} between classes. There exist both probabilistic and non-probabilistic discriminative models.}

\paragraph{Probabilistic Discriminative}

\r{Probabilistic discriminative models learn to estimate the conditional probability i.e. which class is most probable given the input features.}

\paragraph{Non-probabilistic Discriminative}

\r{Non-probabilistic discriminative models directly map features to classes.}

\subsubsection{Generative Models}

% see p129[117] of Mastering ML w/SKL
\TD{TODO: Generative Models --- ``do not learn a decision boundary, rather, they model the joint probability distribution of the features and classes i.e. they model how the classes generate features. Then, using Bayes' theorem, they are able to estimate the conditional probability of a class given the features.''}

\r{must be probabilistic, not deterministic and also some degree of randomness (otherwise the same output would be generated each time).}

\TD{TODO: will need to expand into a much larger section and talk about some types of generative models}

\TD{TODO: ``important'' examples --- GPT2, StyleGAN}

\TD{TODO: use cases -- direct and indirect. music, art, game design, simulations for RL (paper\cite{ha2018world})}

\r{\TD{Generative Deep Learning} makes a point that (paraphrasing) ``categorizing data is not enough, we should try to understand how and why the data came to existence in the first place.''}


% see p130[118] of Mastering ML w/SKL
\r{One advantage of generative models is that they can be used to generate new examples of data}

\subsection{Strong vs Weak Learners}

\TD{TODO: Strong vs Weak learners (classifier, predictor, etc.) overview}
%\textcolor{blue}{}

\begin{itemize}[noitemsep,topsep=0pt]
	\item Strong Learners
	\begin{itemize}[noitemsep,topsep=0pt]
		\item \r{Strong Learners are models that are arbitrarily better than weak learners.}
	\end{itemize}
	\item Weak Learners
	\begin{itemize}[noitemsep,topsep=0pt]
		\item \r{Models (typically simple models) that perform only slightly better than random chance. Typically used in ensemble methods (discussed in more detail in \ALR)}
	\end{itemize}
\end{itemize}

\section{Online Learning}

% See p.246 of Understanding Machine learning
\textcolor{blue}{difference to \textcolor{red}{PAC learning?}}


\section{Kernel Methods}
\label{sec:kernel_trick}

\r{Adding non-linear features to data in attempt linearly separate the data.}

 %Adding non-linear features is a powerful method for allowing linear methods to separate non-linear data. However, which features, combinations of features, and types of features is often not easily known. And adding may of these features may become computationally limiting

\r{Transform the training data onto a higher dimensional feature space}

% see p177[165] of mastering ML with SKL

\r{Choosing an appropriate kernel can be challenging}

% computing the distance (scalar products) of data points for the expanded feature representation --- but doesn't compute the expansion

% see p180[168] of mastering ML w/SKL for more on kernels
\r{Some commonly used kernels include polynomial, RBF, sigmoid, Guassian, and linear kernels}

\r{commonly used in SVMs (see \textcolor{red}{local ref}), the kernel trick can be used with any model that can be expressed in terms of the dot product of two feature vectors.}

\r{the mapping function is not fully computed due to the kernel trick}

\subsection{Kernel Trick}

\subsection{Kernels}

\r{There are many kernel functions. Choosing the ``best'' kernel will depend on the current problem.}

\textcolor{red}{kernel functions are continuous and symmetric}

\textcolor{red}{TODO: put these into context and/or give an example}

\textcolor{blue}{the word kernels is representative of a weighting function \textcolor{red}{or weighted sum or integral}}


% https://data-flair.training/blogs/svm-kernel-functions/
% http://crsouza.com/2010/03/17/kernel-functions-for-machine-learning-applications/

\textcolor{red}{TODO: automatic kernel selection}

\subsubsection{Polynomial}

\r{polynomial computes all possible polynomials of the original features up to a certain degree}

\textcolor{blue}{parameters: slope ($\alpha$), constant $c$, polynomial degree $d$}
\begin{equation}
{k(x, y) = (\alpha x^T y + c)^d}
\label{eq:kernel_polynomial_eq}
\end{equation}
% TODO: double check

\subsubsection{Gaussian / RBF (Radial Basis Function)}

\textcolor{blue}{circles/hypersphere}
\textcolor{red}{infinite-dimensional feature space}

\begin{equation}
{k(x, y) = exp(- \gamma || x_1 - x_2 || ^2 ) }
\label{eq:kernel_guassian_rbf_eq}
\end{equation}

\textcolor{blue}{$|| x_1 - x_2 ||$ represents the euclidean distance and $\gamma$ represents the parameter that controls the width of the Gaussian kernel (the inverse width of the Gaussian kernel). $\gamma$ controls how far the influence of a single training instance reaches --- high values correspond to a limited reach (typically result in lower complexity) and low values correspond to a far reach (typically result in higher complexity).}

\textcolor{green}{Would be nice to have a figure with low - medium - high values for the hyperparameters and the outcome}


\subsection{Less Common Kernels}



%\subsubsection{Laplace RBF}

%\subsubsection{Hyperbolic Tangent}

%\subsubsection{ANOVA Radial Basis Kernel}

%\subsubsection{Sigmoid}

%%%%%%%%%%%%%%%%%%% Hyper-parameters
\input{./nested/basics/hyperparams}

%%%%%%%%%%%%%%%%%%%%%%%% Optimizers

\chapter{Estimating Model Parameters}

\textcolor{green}{Iterative Estimation vs Calculation}

% http://mathworld.wolfram.com/NormalEquation.html
% https://eli.thegreenplace.net/2014/derivation-of-the-normal-equation-for-linear-regression
\textcolor{green}{TODO: Normal Equation}

% TODO: non-invertable (singular or degenerate) matrix

% common causes (not verified) - 1) redundant features 2) too many features - more features than samples. solutions may be to delete features

\input{./nested/basics/initialization}

\chapter{Optimization}

\input{./nested/basics/optimizers}

\chapter{Losses}

\input{./nested/basics/losses}


\input{./nested/basics/genetic_algorithms}

%%%%%%%%%%%%%%%%%%%%%%%% Evaluation
\chapter{Evaluation}

\input{./nested/basics/evaluation}

%%%%%%%%%%% Metrics (subsec nested under sec.Eval)
\input{./nested/basics/metrics}

%%%%%%%%%%%%%%%%%%%%%%%% Regularization
\input{./nested/basics/regularization}


%%%%%%%%%%%%%%%%%%%%%%%% Distributed
\input{./nested/basics/distributed}

\input{./nested/basics/federated}