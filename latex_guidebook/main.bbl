\begin{thebibliography}{100}

\bibitem{cloudHW_amazon_aws}
{\em Amazon aws. [{O}nline]}.
\newblock \url{https://aws.amazon.com/}.
\newblock Accessed: 2018-06-21.

\bibitem{convnet_js}
{\em Convnetjs. [{O}nline]}.
\newblock \url{http://cs.stanford.edu/people/karpathy/convnetjs/}.
\newblock Accessed: 2018-06-21.

\bibitem{cs231n}
{\em Cs231n: Convolutional neural networks for visual recognition}.

\bibitem{deeplearnjs}
{\em deeplearn.js. [{O}nline]}.
\newblock \url{https://deeplearnjs.org/}.
\newblock Accessed: 2018-06-21.

\bibitem{cloudHW_floydhub}
{\em Floydhub. [{O}nline]}.
\newblock \url{https://www.floydhub.com/}.
\newblock Accessed: 2018-06-21.

\bibitem{cloudHW_google_cloud}
{\em Google cloud. [{O}nline]}.
\newblock \url{https://cloud.google.com/gpu/}.
\newblock Accessed: 2018-06-21.

\bibitem{cloudHW_micro_azure}
{\em Microsoft azure. [{O}nline]}.
\newblock
  \url{https://azure.microsoft.com/en-us/pricing/details/virtual-machines/series/}.
\newblock Accessed: 2018-06-21.

\bibitem{tf_playground}
{\em A neural network playground. [{O}nline]}.
\newblock \url{http://playground.tensorflow.org}.
\newblock Accessed: 2018-06-21.

\bibitem{cloudHW_nvidia_cloud}
{\em Nvidia gpu cloud. [{O}nline]}.
\newblock \url{https://www.nvidia.com/en-us/gpu-cloud/}.
\newblock Accessed: 2018-06-21.

\bibitem{abadi2016tensorflow_device_placement}
{\sc M.~Abadi, A.~Agarwal, P.~Barham, E.~Brevdo, Z.~Chen, C.~Citro, G.~S.
  Corrado, A.~Davis, J.~Dean, M.~Devin, et~al.}, {\em Tensorflow: Large-scale
  machine learning on heterogeneous distributed systems}, arXiv preprint
  arXiv:1603.04467,  (2016).

\bibitem{DBLP:journals/corr/abs-1711-08856}
{\sc A.~Achille, M.~Rovere, and S.~Soatto}, {\em Critical learning periods in
  deep neural networks}, CoRR, abs/1711.08856 (2017).

\bibitem{DBLP:journals/corr/abs-1802-04633}
{\sc Y.~Adi, C.~Baum, M.~Ciss{\'{e}}, B.~Pinkas, and J.~Keshet}, {\em Turning
  your weakness into a strength: Watermarking deep neural networks by
  backdooring}, CoRR, abs/1802.04633 (2018).

\bibitem{alber2018backprop}
{\sc M.~Alber, I.~Bello, B.~Zoph, P.-J. Kindermans, P.~Ramachandran, and
  Q.~Le}, {\em Backprop evolution}, arXiv preprint arXiv:1808.02822,  (2018).

\bibitem{Allingham2021SparseMM}
{\sc J.~U. Allingham, F.~Wenzel, Z.~E. Mariet, B.~Mustafa, J.~Puigcerver,
  N.~Houlsby, G.~Jerfel, V.~Fortuin, B.~Lakshminarayanan, J.~Snoek, D.~Tran,
  C.~R. Ruiz, and R.~Jenatton}, {\em Sparse moes meet efficient ensembles},
  2021.

\bibitem{allison2001missing}
{\sc P.~D. Allison}, {\em Missing data}, Sage publications, 2001.

\bibitem{DBLP:journals/corr/AndrychowiczDGH16}
{\sc M.~Andrychowicz, M.~Denil, S.~G. Colmenarejo, M.~W. Hoffman, D.~Pfau,
  T.~Schaul, and N.~de~Freitas}, {\em Learning to learn by gradient descent by
  gradient descent}, CoRR, abs/1606.04474 (2016).

\bibitem{Arjovsky2017WassersteinG}
{\sc M.~Arjovsky, S.~Chintala, and L.~Bottou}, {\em Wasserstein gan}, ArXiv,
  abs/1701.07875 (2017).

\bibitem{Ba2016LayerN}
{\sc J.~Ba, J.~R. Kiros, and G.~E. Hinton}, {\em Layer normalization}, ArXiv,
  abs/1607.06450 (2016).

\bibitem{Bahdanau2015NeuralMT}
{\sc D.~Bahdanau, K.~Cho, and Y.~Bengio}, {\em Neural machine translation by
  jointly learning to align and translate}, CoRR, abs/1409.0473 (2015).

\bibitem{Bansal2020DoesTW}
{\sc G.~Bansal, T.~Wu, J.~Zhu, R.~Fok, B.~Nushi, E.~Kamar, M.~T. Ribeiro, and
  D.~S. Weld}, {\em Does the whole exceed its parts? the effect of ai
  explanations on complementary team performance}, 2020.

\bibitem{DBLP:journals/corr/abs-1904-09330}
{\sc P.~Bashivan, M.~Schrimpf, R.~Ajemian, I.~Rish, M.~Riemer, and Y.~Tu}, {\em
  Continual learning with self-organizing maps}, CoRR, abs/1904.09330 (2019).

\bibitem{DBLP:journals/corr/abs-1106-0245}
{\sc J.~Baxter}, {\em A model of inductive bias learning}, CoRR, abs/1106.0245
  (2011).

\bibitem{baydin2017online}
{\sc A.~G. Baydin, R.~Cornish, D.~M. Rubio, M.~Schmidt, and F.~Wood}, {\em
  Online learning rate adaptation with hypergradient descent}, arXiv preprint
  arXiv:1703.04782,  (2017).

\bibitem{DBLP:journals/corr/abs-1305-2982}
{\sc Y.~Bengio}, {\em Estimating or propagating gradients through stochastic
  neurons}, CoRR, abs/1305.2982 (2013).

\bibitem{box1964analysis}
{\sc G.~E. Box and D.~R. Cox}, {\em An analysis of transformations}, Journal of
  the Royal Statistical Society: Series B (Methodological), 26 (1964),
  pp.~211--243.

\bibitem{DBLP:journals/corr/BrancoTR15}
{\sc P.~Branco, L.~Torgo, and R.~P. Ribeiro}, {\em A survey of predictive
  modelling under imbalanced distributions}, CoRR, abs/1505.01658 (2015).

\bibitem{DBLP:journals/corr/BritzGLL17}
{\sc D.~Britz, A.~Goldie, M.~Luong, and Q.~V. Le}, {\em Massive exploration of
  neural machine translation architectures}, CoRR, abs/1703.03906 (2017).

\bibitem{bromley1994signature}
{\sc J.~Bromley, I.~Guyon, Y.~LeCun, E.~S{\"a}ckinger, and R.~Shah}, {\em
  Signature verification using a" siamese" time delay neural network}, in
  Advances in neural information processing systems, 1994, pp.~737--744.

\bibitem{Carion2020EndtoEndOD}
{\sc N.~Carion, F.~Massa, G.~Synnaeve, N.~Usunier, A.~M. Kirillov, and
  S.~Zagoruyko}, {\em End-to-end object detection with transformers}, ArXiv,
  abs/2005.12872 (2020).

\bibitem{DBLP:journals/corr/CarliniW16a}
{\sc N.~Carlini and D.~A. Wagner}, {\em Towards evaluating the robustness of
  neural networks}, CoRR, abs/1608.04644 (2016).

\bibitem{Caron2020UnsupervisedLO}
{\sc M.~Caron, I.~Misra, J.~Mairal, P.~Goyal, P.~Bojanowski, and A.~Joulin},
  {\em Unsupervised learning of visual features by contrasting cluster
  assignments}, ArXiv, abs/2006.09882 (2020).

\bibitem{caruana1993multitask}
{\sc R.~Caruana}, {\em Multitask learning: A knowledge-based source of
  inductive bias icml}, Google Scholar Google Scholar Digital Library Digital
  Library,  (1993).

\bibitem{DBLP:journals/corr/abs-1810-00069}
{\sc A.~Chakraborty, M.~Alam, V.~Dey, A.~Chattopadhyay, and D.~Mukhopadhyay},
  {\em Adversarial attacks and defences: {A} survey}, CoRR, abs/1810.00069
  (2018).

\bibitem{Chen2020ASF}
{\sc T.~Chen, S.~Kornblith, M.~Norouzi, and G.~E. Hinton}, {\em A simple
  framework for contrastive learning of visual representations}, ArXiv,
  abs/2002.05709 (2020).

\bibitem{Chen2020BigSM}
{\sc T.~Chen, S.~Kornblith, K.~Swersky, M.~Norouzi, and G.~E. Hinton}, {\em Big
  self-supervised models are strong semi-supervised learners}, ArXiv,
  abs/2006.10029 (2020).

\bibitem{DBLP:journals/corr/abs-1806-07366}
{\sc T.~Q. Chen, Y.~Rubanova, J.~Bettencourt, and D.~Duvenaud}, {\em Neural
  ordinary differential equations}, CoRR, abs/1806.07366 (2018).

\bibitem{DBLP:journals/corr/ChenCZH17}
{\sc W.~Chen, X.~Chen, J.~Zhang, and K.~Huang}, {\em Beyond triplet loss: a
  deep quadruplet network for person re-identification}, CoRR, abs/1704.01719
  (2017).

\bibitem{Chen2020ImprovedBW}
{\sc X.~Chen, H.~Fan, R.~B. Girshick, and K.~He}, {\em Improved baselines with
  momentum contrastive learning}, ArXiv, abs/2003.04297 (2020).

\bibitem{Chen2020ExploringSS}
{\sc X.~Chen and K.~He}, {\em Exploring simple siamese representation
  learning}, ArXiv, abs/2011.10566 (2020).

\bibitem{DBLP:journals/corr/ChengDL16}
{\sc J.~Cheng, L.~Dong, and M.~Lapata}, {\em Long short-term memory-networks
  for machine reading}, CoRR, abs/1601.06733 (2016).

\bibitem{DBLP:journals/corr/abs-1904-10509}
{\sc R.~Child, S.~Gray, A.~Radford, and I.~Sutskever}, {\em Generating long
  sequences with sparse transformers}, CoRR, abs/1904.10509 (2019).

\bibitem{Chuang2020DebiasedCL}
{\sc C.-Y. Chuang, J.~A. Robinson, L.~Yen‚ÄêChen, A.~Torralba, and S.~Jegelka},
  {\em Debiased contrastive learning}, 2020.

\bibitem{Cordonnier2020MultiHeadAC}
{\sc J.-B. Cordonnier, A.~Loukas, and M.~Jaggi}, {\em Multi-head attention:
  Collaborate instead of concatenate}, ArXiv, abs/2006.16362 (2020).

\bibitem{DBLP:journals/corr/CourbariauxB16}
{\sc M.~Courbariaux and Y.~Bengio}, {\em Binarynet: Training deep neural
  networks with weights and activations constrained to +1 or -1}, CoRR,
  abs/1602.02830 (2016).

\bibitem{DBLP:journals/corr/abs-2009-09796}
{\sc M.~Crawshaw}, {\em Multi-task learning with deep neural networks: {A}
  survey}, CoRR, abs/2009.09796 (2020).

\bibitem{cubuk2018autoaugment}
{\sc E.~D. Cubuk, B.~Zoph, D.~Mane, V.~Vasudevan, and Q.~V. Le}, {\em
  Autoaugment: Learning augmentation policies from data}, arXiv preprint
  arXiv:1805.09501,  (2018).

\bibitem{DBLP:journals/corr/abs-1901-02860}
{\sc Z.~Dai, Z.~Yang, Y.~Yang, J.~G. Carbonell, Q.~V. Le, and
  R.~Salakhutdinov}, {\em Transformer-xl: Attentive language models beyond a
  fixed-length context}, CoRR, abs/1901.02860 (2019).

\bibitem{davis2006relationship}
{\sc J.~Davis and M.~Goadrich}, {\em The relationship between precision-recall
  and roc curves}, in Proceedings of the 23rd international conference on
  Machine learning, 2006, pp.~233--240.

\bibitem{deng2013improving}
{\sc A.~Deng, Y.~Xu, R.~Kohavi, and T.~Walker}, {\em Improving the sensitivity
  of online controlled experiments by utilizing pre-experiment data}, in
  Proceedings of the sixth ACM international conference on Web search and data
  mining, 2013, pp.~123--132.

\bibitem{devries2017improved}
{\sc T.~DeVries and G.~W. Taylor}, {\em Improved regularization of
  convolutional neural networks with cutout}, arXiv preprint arXiv:1708.04552,
  (2017).

\bibitem{Ding2021RepMLPRC}
{\sc X.~Ding, X.~Zhang, J.~Han, and G.~Ding}, {\em Repmlp: Re-parameterizing
  convolutions into fully-connected layers for image recognition}, ArXiv,
  abs/2105.01883 (2021).

\bibitem{Doersch2016TutorialOV}
{\sc C.~Doersch}, {\em Tutorial on variational autoencoders}, ArXiv,
  abs/1606.05908 (2016).

\bibitem{dozat2016incorporating}
{\sc T.~Dozat}, {\em Incorporating nesterov momentum into adam},  (2016).

\bibitem{Du2019SpineNetLS}
{\sc X.~Du, T.-Y. Lin, P.~Jin, G.~Ghiasi, M.~Tan, Y.~Cui, Q.~V. Le, and
  X.~Song}, {\em Spinenet: Learning scale-permuted backbone for recognition and
  localization}, ArXiv, abs/1912.05027 (2019).

\bibitem{duchi2011adaptive}
{\sc J.~Duchi, E.~Hazan, and Y.~Singer}, {\em Adaptive subgradient methods for
  online learning and stochastic optimization}, Journal of Machine Learning
  Research, 12 (2011), pp.~2121--2159.

\bibitem{DBLP:journals/corr/abs-1812-03128}
{\sc J.~Dumford and W.~J. Scheirer}, {\em Backdooring convolutional neural
  networks via targeted weight perturbations}, CoRR, abs/1812.03128 (2018).

\bibitem{duong2015low}
{\sc L.~Duong, T.~Cohn, S.~Bird, and P.~Cook}, {\em Low resource dependency
  parsing: Cross-lingual parameter sharing in a neural network parser}, in
  Proceedings of the 53rd Annual Meeting of the Association for Computational
  Linguistics and the 7th International Joint Conference on Natural Language
  Processing (Volume 2: Short Papers), 2015, pp.~845--850.

\bibitem{Evci2019RiggingTL}
{\sc U.~Evci, T.~Gale, J.~Menick, P.~S. Castro, and E.~Elsen}, {\em Rigging the
  lottery: Making all tickets winners}, ArXiv, abs/1911.11134 (2019).

\bibitem{fisher1992statistical}
{\sc R.~A. Fisher}, {\em Statistical methods for research workers}, in
  Breakthroughs in statistics, Springer, 1992, pp.~66--70.

\bibitem{foster2019generative}
{\sc D.~Foster}, {\em Generative deep learning: teaching machines to paint,
  write, compose, and play}, O'Reilly Media, 2019.

\bibitem{DBLP:journals/corr/abs-1803-03635}
{\sc J.~Frankle and M.~Carbin}, {\em The lottery ticket hypothesis: Training
  pruned neural networks}, CoRR, abs/1803.03635 (2018).

\bibitem{Frankle2020PruningNN}
{\sc J.~Frankle, G.~Dziugaite, D.~M. Roy, and M.~Carbin}, {\em Pruning neural
  networks at initialization: Why are we missing the mark?}, 2020.

\bibitem{DBLP:journals/corr/abs-1903-01611}
{\sc J.~Frankle, G.~K. Dziugaite, D.~M. Roy, and M.~Carbin}, {\em The lottery
  ticket hypothesis at scale}, CoRR, abs/1903.01611 (2019).

\bibitem{Frankle2020TheEP}
{\sc J.~Frankle, D.~J. Schwab, and A.~S. Morcos}, {\em The early phase of
  neural network training}, ArXiv, abs/2002.10365 (2020).

\bibitem{fukushima1982neocognitron}
{\sc K.~Fukushima and S.~Miyake}, {\em Neocognitron: A self-organizing neural
  network model for a mechanism of visual pattern recognition}, in Competition
  and cooperation in neural nets, Springer, 1982, pp.~267--285.

\bibitem{DBLP:journals/corr/abs-1906-04358}
{\sc A.~Gaier and D.~Ha}, {\em Weight agnostic neural networks}, CoRR,
  abs/1906.04358 (2019).

\bibitem{garnelo2018conditional}
{\sc M.~Garnelo, D.~Rosenbaum, C.~J. Maddison, T.~Ramalho, D.~Saxton,
  M.~Shanahan, Y.~W. Teh, D.~J. Rezende, and S.~Eslami}, {\em Conditional
  neural processes}, arXiv preprint arXiv:1807.01613,  (2018).

\bibitem{DBLP:journals/corr/abs-1807-01622}
{\sc M.~Garnelo, J.~Schwarz, D.~Rosenbaum, F.~Viola, D.~J. Rezende, S.~M.~A.
  Eslami, and Y.~W. Teh}, {\em Neural processes}, CoRR, abs/1807.01622 (2018).

\bibitem{geron2019hands}
{\sc A.~G{\'e}ron}, {\em Hands-on machine learning with Scikit-Learn, Keras,
  and TensorFlow: Concepts, tools, and techniques to build intelligent
  systems}, O'Reilly Media, 2019.

\bibitem{Ghorbani2019DermGANSG}
{\sc A.~Ghorbani, V.~Natarajan, D.~Coz, and Y.~Liu}, {\em Dermgan: Synthetic
  generation of clinical skin images with pathology}, ArXiv, abs/1911.08716
  (2019).

\bibitem{glorot2010understanding}
{\sc X.~Glorot and Y.~Bengio}, {\em Understanding the difficulty of training
  deep feedforward neural networks}, in Proceedings of the thirteenth
  international conference on artificial intelligence and statistics, 2010,
  pp.~249--256.

\bibitem{Goodfellow2014GenerativeAN}
{\sc I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley,
  S.~Ozair, A.~C. Courville, and Y.~Bengio}, {\em Generative adversarial
  networks}, ArXiv, abs/1406.2661 (2014).

\bibitem{DBLP:journals/corr/Goodfellow17}
{\sc I.~J. Goodfellow}, {\em Nips 2016 tutorial: Generative adversarial
  networks}, CoRR, abs/1701.00160 (2017).

\bibitem{Goodfellow2015ExplainingAH}
{\sc I.~J. Goodfellow, J.~Shlens, and C.~Szegedy}, {\em Explaining and
  harnessing adversarial examples}, CoRR, abs/1412.6572 (2015).

\bibitem{Goyal2019RecurrentIM}
{\sc A.~Goyal, A.~Lamb, J.~Hoffmann, S.~Sodhani, S.~Levine, Y.~Bengio, and
  B.~Sch{\"o}lkopf}, {\em Recurrent independent mechanisms}, ArXiv,
  abs/1909.10893 (2019).

\bibitem{Goyal2021SelfsupervisedPO}
{\sc P.~Goyal, M.~Caron, B.~Lefaudeux, M.~Xu, P.~Wang, V.~Pai, M.~Singh,
  V.~Liptchinsky, I.~Misra, A.~Joulin, and P.~Bojanowski}, {\em Self-supervised
  pretraining of visual features in the wild}, ArXiv, abs/2103.01988 (2021).

\bibitem{DBLP:journals/corr/GravesWD14}
{\sc A.~Graves, G.~Wayne, and I.~Danihelka}, {\em Neural turing machines},
  CoRR, abs/1410.5401 (2014).

\bibitem{DBLP:journals/corr/GreffSKSS15}
{\sc K.~Greff, R.~K. Srivastava, J.~Koutn{\'{\i}}k, B.~R. Steunebrink, and
  J.~Schmidhuber}, {\em {LSTM:} {A} search space odyssey}, CoRR, abs/1503.04069
  (2015).

\bibitem{griewank2008evaluating}
{\sc A.~Griewank and A.~Walther}, {\em Evaluating derivatives: principles and
  techniques of algorithmic differentiation}, vol.~105, Siam, 2008.

\bibitem{Grill2020BootstrapYO}
{\sc J.-B. Grill, F.~Strub, F.~Altch{\'e}, C.~Tallec, P.~H. Richemond,
  E.~Buchatskaya, C.~Doersch, B.~A. Pires, Z.~D. Guo, M.~G. Azar, B.~Piot,
  K.~Kavukcuoglu, R.~Munos, and M.~Valko}, {\em Bootstrap your own latent: A
  new approach to self-supervised learning}, ArXiv, abs/2006.07733 (2020).

\bibitem{Gu2015TowardsDN}
{\sc S.~Gu and L.~Rigazio}, {\em Towards deep neural network architectures
  robust to adversarial examples}, CoRR, abs/1412.5068 (2015).

\bibitem{DBLP:journals/corr/abs-1708-06733}
{\sc T.~Gu, B.~Dolan{-}Gavitt, and S.~Garg}, {\em Badnets: Identifying
  vulnerabilities in the machine learning model supply chain}, CoRR,
  abs/1708.06733 (2017).

\bibitem{DBLP:journals/corr/GulrajaniAADC17}
{\sc I.~Gulrajani, F.~Ahmed, M.~Arjovsky, V.~Dumoulin, and A.~C. Courville},
  {\em Improved training of wasserstein gans}, CoRR, abs/1704.00028 (2017).

\bibitem{guo2016entity}
{\sc C.~Guo and F.~Berkhahn}, {\em Entity embeddings of categorical variables},
  arXiv preprint arXiv:1604.06737,  (2016).

\bibitem{DBLP:journals/corr/GuoPSW17}
{\sc C.~Guo, G.~Pleiss, Y.~Sun, and K.~Q. Weinberger}, {\em On calibration of
  modern neural networks}, CoRR, abs/1706.04599 (2017).

\bibitem{DBLP:journals/corr/GuptaCPVCMM15}
{\sc M.~R. Gupta, A.~Cotter, J.~Pfeifer, K.~Voevodski, K.~R. Canini,
  A.~Mangylov, and W.~Moczydlowski}, {\em Monotonic calibrated interpolated
  look-up tables}, CoRR, abs/1505.06378 (2015).

\bibitem{ha2018world}
{\sc D.~Ha and J.~Schmidhuber}, {\em World models}, arXiv preprint
  arXiv:1803.10122,  (2018).

\bibitem{hansen1990neural}
{\sc L.~K. Hansen and P.~Salamon}, {\em Neural network ensembles}, IEEE
  Transactions on Pattern Analysis \& Machine Intelligence,  (1990),
  pp.~993--1001.

\bibitem{DBLP:journals/corr/HashimotoXTS16}
{\sc K.~Hashimoto, C.~Xiong, Y.~Tsuruoka, and R.~Socher}, {\em A joint
  many-task model: Growing a neural network for multiple {NLP} tasks}, CoRR,
  abs/1611.01587 (2016).

\bibitem{DBLP:journals/corr/abs-2010-06610}
{\sc M.~Havasi, R.~Jenatton, S.~Fort, J.~Z. Liu, J.~Snoek, B.~Lakshminarayanan,
  A.~M. Dai, and D.~Tran}, {\em Training independent subnetworks for robust
  prediction}, CoRR, abs/2010.06610 (2020).

\bibitem{DBLP:journals/corr/abs-1911-05722}
{\sc K.~He, H.~Fan, Y.~Wu, S.~Xie, and R.~B. Girshick}, {\em Momentum contrast
  for unsupervised visual representation learning}, CoRR, abs/1911.05722
  (2019).

\bibitem{DBLP:journals/corr/HeGDG17}
{\sc K.~He, G.~Gkioxari, P.~Doll{\'{a}}r, and R.~B. Girshick}, {\em Mask
  {R-CNN}}, CoRR, abs/1703.06870 (2017).

\bibitem{DBLP:journals/corr/HeZRS15}
{\sc K.~He, X.~Zhang, S.~Ren, and J.~Sun}, {\em Deep residual learning for
  image recognition}, CoRR, abs/1512.03385 (2015).

\bibitem{he2015delving}
{\sc K.~He, X.~Zhang, S.~Ren, and J.~Sun}, {\em Delving deep into rectifiers:
  Surpassing human-level performance on imagenet classification}, in
  Proceedings of the IEEE international conference on computer vision, 2015,
  pp.~1026--1034.

\bibitem{DBLP:journals/corr/abs-1812-01187}
{\sc T.~He, Z.~Zhang, H.~Zhang, Z.~Zhang, J.~Xie, and M.~Li}, {\em Bag of
  tricks for image classification with convolutional neural networks}, CoRR,
  abs/1812.01187 (2018).

\bibitem{DBLP:journals/corr/abs-2102-01293}
{\sc D.~Hernandez, J.~Kaplan, T.~Henighan, and S.~McCandlish}, {\em Scaling
  laws for transfer}, CoRR, abs/2102.01293 (2021).

\bibitem{hinton2015distilling}
{\sc G.~Hinton, O.~Vinyals, and J.~Dean}, {\em Distilling the knowledge in a
  neural network}, arXiv preprint arXiv:1503.02531,  (2015).

\bibitem{DBLP:journals/corr/abs-1207-0580}
{\sc G.~E. Hinton, N.~Srivastava, A.~Krizhevsky, I.~Sutskever, and
  R.~Salakhutdinov}, {\em Improving neural networks by preventing co-adaptation
  of feature detectors}, CoRR, abs/1207.0580 (2012).

\bibitem{Hinton2015DistillingTK}
{\sc G.~E. Hinton, O.~Vinyals, and J.~Dean}, {\em Distilling the knowledge in a
  neural network}, ArXiv, abs/1503.02531 (2015).

\bibitem{ho2019population}
{\sc D.~Ho, E.~Liang, I.~Stoica, P.~Abbeel, and X.~Chen}, {\em Population based
  augmentation: Efficient learning of augmentation policy schedules}, arXiv
  preprint arXiv:1905.05393,  (2019).

\bibitem{hoffer2017train}
{\sc E.~Hoffer, I.~Hubara, and D.~Soudry}, {\em Train longer, generalize
  better: closing the generalization gap in large batch training of neural
  networks}, in Advances in Neural Information Processing Systems, 2017,
  pp.~1729--1739.

\bibitem{Hooker2020TheHL}
{\sc S.~Hooker}, {\em The hardware lottery}, ArXiv, abs/2009.06489 (2020).

\bibitem{hornik1991approximation}
{\sc K.~Hornik}, {\em Approximation capabilities of multilayer feedforward
  networks}, Neural networks, 4 (1991), pp.~251--257.

\bibitem{DBLP:journals/corr/abs-1709-01507}
{\sc J.~Hu, L.~Shen, and G.~Sun}, {\em Squeeze-and-excitation networks}, CoRR,
  abs/1709.01507 (2017).

\bibitem{huang2017snapshot}
{\sc G.~Huang, Y.~Li, G.~Pleiss, Z.~Liu, J.~E. Hopcroft, and K.~Q. Weinberger},
  {\em Snapshot ensembles: Train 1, get m for free}, arXiv preprint
  arXiv:1704.00109,  (2017).

\bibitem{DBLP:journals/corr/HuangLW16a}
{\sc G.~Huang, Z.~Liu, and K.~Q. Weinberger}, {\em Densely connected
  convolutional networks}, CoRR, abs/1608.06993 (2016).

\bibitem{DBLP:journals/corr/IandolaMAHDK16}
{\sc F.~N. Iandola, M.~W. Moskewicz, K.~Ashraf, S.~Han, W.~J. Dally, and
  K.~Keutzer}, {\em Squeezenet: Alexnet-level accuracy with 50x fewer
  parameters and {\textless}1mb model size}, CoRR, abs/1602.07360 (2016).

\bibitem{inoue2018data}
{\sc H.~Inoue}, {\em Data augmentation by pairing samples for images
  classification}, arXiv preprint arXiv:1801.02929,  (2018).

\bibitem{DBLP:journals/corr/IoffeS15}
{\sc S.~Ioffe and C.~Szegedy}, {\em Batch normalization: Accelerating deep
  network training by reducing internal covariate shift}, CoRR, abs/1502.03167
  (2015).

\bibitem{DBLP:journals/corr/abs-2107-14795}
{\sc A.~Jaegle, S.~Borgeaud, J.~Alayrac, C.~Doersch, C.~Ionescu, D.~Ding,
  S.~Koppula, D.~Zoran, A.~Brock, E.~Shelhamer, O.~J. H{\'{e}}naff, M.~M.
  Botvinick, A.~Zisserman, O.~Vinyals, and J.~Carreira}, {\em Perceiver {IO:}
  {A} general architecture for structured inputs {\&} outputs}, CoRR,
  abs/2107.14795 (2021).

\bibitem{Jaegle2021PerceiverGP}
{\sc A.~Jaegle, F.~Gimeno, A.~Brock, A.~Zisserman, O.~Vinyals, and
  J.~Carreira}, {\em Perceiver: General perception with iterative attention},
  ArXiv, abs/2103.03206 (2021).

\bibitem{DBLP:journals/corr/abs-2103-03206}
{\sc A.~Jaegle, F.~Gimeno, A.~Brock, A.~Zisserman, O.~Vinyals, and
  J.~Carreira}, {\em Perceiver: General perception with iterative attention},
  CoRR, abs/2103.03206 (2021).

\bibitem{jiang2020exploring}
{\sc Z.~Jiang, C.~Zhang, K.~Talwar, and M.~C. Mozer}, {\em Exploring the
  memorization-generalization continuum in deep learning}, arXiv preprint
  arXiv:2002.03206,  (2020).

\bibitem{Kairouz2019AdvancesAO}
{\sc P.~Kairouz, H.~B. McMahan, B.~Avent, A.~Bellet, M.~Bennis, A.~N. Bhagoji,
  K.~Bonawitz, Z.~Charles, G.~Cormode, R.~Cummings, R.~G.~L. D'Oliveira, S.~E.
  Rouayheb, D.~Evans, J.~Gardner, Z.~A. Garrett, A.~Gasc{\'o}n, B.~Ghazi, P.~B.
  Gibbons, M.~Gruteser, Z.~Harchaoui, C.~He, L.~He, Z.~Huo, B.~Hutchinson,
  J.~Hsu, M.~Jaggi, T.~Javidi, G.~Joshi, M.~Khodak, J.~Konecn{\'y},
  A.~Korolova, F.~Koushanfar, O.~Koyejo, T.~Lepoint, Y.~Liu, P.~Mittal,
  M.~Mohri, R.~Nock, A.~{\"O}zg{\"u}r, R.~Pagh, M.~Raykova, H.~Qi, D.~Ramage,
  R.~Raskar, D.~X. Song, W.~Song, S.~U. Stich, Z.~Sun, A.~T. Suresh,
  F.~Tram{\`e}r, P.~Vepakomma, J.~Wang, L.~Xiong, Z.~Xu, Q.~Yang, F.~X. Yu,
  H.~Yu, and S.~Zhao}, {\em Advances and open problems in federated learning},
  ArXiv, abs/1912.04977 (2019).

\bibitem{DBLP:journals/corr/KaiserGSVPJU17}
{\sc L.~Kaiser, A.~N. Gomez, N.~Shazeer, A.~Vaswani, N.~Parmar, L.~Jones, and
  J.~Uszkoreit}, {\em One model to learn them all}, CoRR, abs/1706.05137
  (2017).

\bibitem{Kalchbrenner2016GridLS}
{\sc N.~Kalchbrenner, I.~Danihelka, and A.~Graves}, {\em Grid long short-term
  memory}, CoRR, abs/1507.01526 (2016).

\bibitem{Katharopoulos2020TransformersAR}
{\sc A.~Katharopoulos, A.~Vyas, N.~Pappas, and F.~Fleuret}, {\em Transformers
  are rnns: Fast autoregressive transformers with linear attention}, ArXiv,
  abs/2006.16236 (2020).

\bibitem{kaya2019deep}
{\sc M.~Kaya and H.~{\c{S}}. Bilge}, {\em Deep metric learning: A survey},
  Symmetry, 11 (2019), p.~1066.

\bibitem{Ke2020RethinkingPE}
{\sc G.~Ke, D.~He, and T.-Y. Liu}, {\em Rethinking positional encoding in
  language pre-training}, ArXiv, abs/2006.15595 (2020).

\bibitem{DBLP:journals/corr/KendallGC17}
{\sc A.~Kendall, Y.~Gal, and R.~Cipolla}, {\em Multi-task learning using
  uncertainty to weigh losses for scene geometry and semantics}, CoRR,
  abs/1705.07115 (2017).

\bibitem{Khacef2020ImprovingSM}
{\sc L.~Khacef, L.~Rodriguez, and B.~Miramond}, {\em Improving self-organizing
  maps with unsupervised feature extraction}, ArXiv, abs/2009.02174 (2020).

\bibitem{DBLP:journals/corr/abs-1901-06032}
{\sc A.~Khan, A.~Sohail, U.~Zahoora, and A.~S. Qureshi}, {\em A survey of the
  recent architectures of deep convolutional neural networks}, CoRR,
  abs/1901.06032 (2019).

\bibitem{kingma2014adam}
{\sc D.~P. Kingma and J.~Ba}, {\em Adam: A method for stochastic optimization},
  arXiv preprint arXiv:1412.6980,  (2014).

\bibitem{Kingma2014AutoEncodingVB}
{\sc D.~P. Kingma and M.~Welling}, {\em Auto-encoding variational bayes}, CoRR,
  abs/1312.6114 (2014).

\bibitem{kirillov2019panoptic}
{\sc A.~Kirillov, R.~Girshick, K.~He, and P.~Doll{\'a}r}, {\em Panoptic feature
  pyramid networks}, in Proceedings of the IEEE Conference on Computer Vision
  and Pattern Recognition, 2019, pp.~6399--6408.

\bibitem{Kirillov2019PointRendIS}
{\sc A.~M. Kirillov, Y.~Wu, K.~He, and R.~B. Girshick}, {\em Pointrend: Image
  segmentation as rendering}, ArXiv, abs/1912.08193 (2019).

\bibitem{Kitaev2020ReformerTE}
{\sc N.~Kitaev, L.~Kaiser, and A.~Levskaya}, {\em Reformer: The efficient
  transformer}, ArXiv, abs/2001.04451 (2020).

\bibitem{DBLP:journals/corr/KlambauerUMH17}
{\sc G.~Klambauer, T.~Unterthiner, A.~Mayr, and S.~Hochreiter}, {\em
  Self-normalizing neural networks}, CoRR, abs/1706.02515 (2017).

\bibitem{kochenderfer2019algorithms}
{\sc M.~J. Kochenderfer and T.~A. Wheeler}, {\em Algorithms for Optimization},
  Mit Press, 2019.

\bibitem{DBLP:journals/corr/KoutnikGGS14}
{\sc J.~Koutn{\'{\i}}k, K.~Greff, F.~J. Gomez, and J.~Schmidhuber}, {\em A
  clockwork {RNN}}, CoRR, abs/1402.3511 (2014).

\bibitem{krawczyk2016learning}
{\sc B.~Krawczyk}, {\em Learning from imbalanced data: open challenges and
  future directions}, Progress in Artificial Intelligence, 5 (2016),
  pp.~221--232.

\bibitem{lakshmanan2021practical}
{\sc V.~Lakshmanan, M.~G{\"o}rner, and R.~Gillard}, {\em Practical Machine
  Learning for Computer Vision: End-To-End Machine Learning for Images},
  O'Reilly Media, Incorporated, 2021.

\bibitem{lange2020_lottery_ticket_hypothesis}
{\sc R.~T. Lange}, {\em The lottery ticket hypothesis: A survey},
  https://roberttlange.github.io/year-archive/posts/2020/06/lottery-ticket-hypothesis/,
   (2020).

\bibitem{DBLP:journals/corr/abs-2010-05113}
{\sc P.~H. Le{-}Khac, G.~Healy, and A.~F. Smeaton}, {\em Contrastive
  representation learning: {A} framework and review}, CoRR, abs/2010.05113
  (2020).

\bibitem{lecun2012efficient}
{\sc Y.~A. LeCun, L.~Bottou, G.~B. Orr, and K.-R. M{\"u}ller}, {\em Efficient
  backprop}, in Neural networks: Tricks of the trade, Springer, 2012,
  pp.~9--48.

\bibitem{lee2013pseudo}
{\sc D.-H. Lee}, {\em Pseudo-label: The simple and efficient semi-supervised
  learning method for deep neural networks}, in Workshop on challenges in
  representation learning, ICML, vol.~3, 2013.

\bibitem{DBLP:journals/corr/abs-1810-02340}
{\sc N.~Lee, T.~Ajanthan, and P.~H.~S. Torr}, {\em {SNIP:} single-shot network
  pruning based on connection sensitivity}, CoRR, abs/1810.02340 (2018).

\bibitem{lemley2017smart}
{\sc J.~Lemley, S.~Bazrafkan, and P.~Corcoran}, {\em Smart augmentation
  learning an optimal data augmentation strategy}, Ieee Access, 5 (2017),
  pp.~5858--5869.

\bibitem{Lepikhin2020GShardSG}
{\sc D.~Lepikhin, H.~Lee, Y.~Xu, D.~Chen, O.~Firat, Y.-P. Huang, M.~Krikun,
  N.~Shazeer, and Z.~Chen}, {\em Gshard: Scaling giant models with conditional
  computation and automatic sharding}, ArXiv, abs/2006.16668 (2020).

\bibitem{Lewkowycz2020TheLL}
{\sc A.~Lewkowycz, Y.~Bahri, E.~Dyer, J.~Sohl-Dickstein, and G.~Gur-Ari}, {\em
  The large learning rate phase of deep learning: the catapult mechanism},
  ArXiv, abs/2003.02218 (2020).

\bibitem{DBLP:journals/corr/abs-1712-09913}
{\sc H.~Li, Z.~Xu, G.~Taylor, and T.~Goldstein}, {\em Visualizing the loss
  landscape of neural nets}, CoRR, abs/1712.09913 (2017).

\bibitem{Li2020BackdoorLA}
{\sc Y.~Li, B.~Wu, Y.~Jiang, Z.~Li, and S.-T. Xia}, {\em Backdoor learning: A
  survey}, ArXiv, abs/2007.08745 (2020).

\bibitem{lim2019fast}
{\sc S.~Lim, I.~Kim, T.~Kim, C.~Kim, and S.~Kim}, {\em Fast autoaugment}, arXiv
  preprint arXiv:1905.00397,  (2019).

\bibitem{DBLP:journals/corr/abs-1708-02002}
{\sc T.~Lin, P.~Goyal, R.~B. Girshick, K.~He, and P.~Doll{\'{a}}r}, {\em Focal
  loss for dense object detection}, CoRR, abs/1708.02002 (2017).

\bibitem{linnainmaa1970representation}
{\sc S.~Linnainmaa}, {\em The representation of the cumulative rounding error
  of an algorithm as a taylor expansion of the local rounding errors}, Master's
  Thesis (in Finnish), Univ. Helsinki,  (1970), pp.~6--7.

\bibitem{Liu2021PayAT}
{\sc H.~Liu, Z.~Dai, D.~R. So, and Q.~V. Le}, {\em Pay attention to mlps},
  ArXiv, abs/2105.08050 (2021).

\bibitem{DBLP:journals/corr/abs-1803-10704}
{\sc S.~Liu, E.~Johns, and A.~J. Davison}, {\em End-to-end multi-task learning
  with attention}, CoRR, abs/1803.10704 (2018).

\bibitem{DBLP:journals/corr/LiuAESR15}
{\sc W.~Liu, D.~Anguelov, D.~Erhan, C.~Szegedy, S.~E. Reed, C.~Fu, and A.~C.
  Berg}, {\em {SSD:} single shot multibox detector}, CoRR, abs/1512.02325
  (2015).

\bibitem{Liu2020SelfpacedEF}
{\sc Z.~Liu, W.~Cao, Z.~Gao, J.~Bian, H.~Chen, Y.~Chang, and T.~Liu}, {\em
  Self-paced ensemble for highly imbalanced massive data classification}, 2020
  IEEE 36th International Conference on Data Engineering (ICDE),  (2020),
  pp.~841--852.

\bibitem{Locatello2020ObjectCentricLW}
{\sc F.~Locatello, D.~Weissenborn, T.~Unterthiner, A.~Mahendran, G.~Heigold,
  J.~Uszkoreit, A.~Dosovitskiy, and T.~Kipf}, {\em Object-centric learning with
  slot attention}, ArXiv, abs/2006.15055 (2020).

\bibitem{DBLP:journals/corr/Long015a}
{\sc M.~Long and J.~Wang}, {\em Learning multiple tasks with deep relationship
  networks}, CoRR, abs/1506.02117 (2015).

\bibitem{loshchilov2016sgdr}
{\sc I.~Loshchilov and F.~Hutter}, {\em Sgdr: stochastic gradient descent with
  restarts}, Learning, 10 (2016), p.~3.

\bibitem{DBLP:journals/corr/LuKZCJF16}
{\sc Y.~Lu, A.~Kumar, S.~Zhai, Y.~Cheng, T.~Javidi, and R.~S. Feris}, {\em
  Fully-adaptive feature sharing in multi-task networks with applications in
  person attribute classification}, CoRR, abs/1611.05377 (2016).

\bibitem{DBLP:journals/corr/LuongPM15}
{\sc M.~Luong, H.~Pham, and C.~D. Manning}, {\em Effective approaches to
  attention-based neural machine translation}, CoRR, abs/1508.04025 (2015).

\bibitem{ma2018modeling}
{\sc J.~Ma, Z.~Zhao, X.~Yi, J.~Chen, L.~Hong, and E.~H. Chi}, {\em Modeling
  task relationships in multi-task learning with multi-gate
  mixture-of-experts}, in Proceedings of the 24th ACM SIGKDD International
  Conference on Knowledge Discovery \& Data Mining, 2018, pp.~1930--1939.

\bibitem{Madry2018TowardsDL}
{\sc A.~Madry, A.~Makelov, L.~Schmidt, D.~Tsipras, and A.~Vladu}, {\em Towards
  deep learning models resistant to adversarial attacks}, ArXiv, abs/1706.06083
  (2018).

\bibitem{mangalam2019deep}
{\sc K.~Mangalam and V.~U. Prabhu}, {\em Do deep neural networks learn shallow
  learnable examples first?},  (2019).

\bibitem{masters2018revisiting}
{\sc D.~Masters and C.~Luschi}, {\em Revisiting small batch training for deep
  neural networks}, arXiv preprint arXiv:1804.07612,  (2018).

\bibitem{MelasKyriazi2021DoYE}
{\sc L.~Melas-Kyriazi}, {\em Do you even need attention? a stack of
  feed-forward layers does surprisingly well on imagenet}, ArXiv,
  abs/2105.02723 (2021).

\bibitem{DBLP:journals/corr/MisraSGH16}
{\sc I.~Misra, A.~Shrivastava, A.~Gupta, and M.~Hebert}, {\em Cross-stitch
  networks for multi-task learning}, CoRR, abs/1604.03539 (2016).

\bibitem{DBLP:journals/corr/abs-2104-12871}
{\sc M.~Mitchell}, {\em Why {AI} is harder than we think}, CoRR, abs/2104.12871
  (2021).

\bibitem{DBLP:journals/corr/abs-1810-03993}
{\sc M.~Mitchell, S.~Wu, A.~Zaldivar, P.~Barnes, L.~Vasserman, B.~Hutchinson,
  E.~Spitzer, I.~D. Raji, and T.~Gebru}, {\em Model cards for model reporting},
  CoRR, abs/1810.03993 (2018).

\bibitem{miyato2018virtual}
{\sc T.~Miyato, S.-i. Maeda, M.~Koyama, and S.~Ishii}, {\em Virtual adversarial
  training: a regularization method for supervised and semi-supervised
  learning}, IEEE transactions on pattern analysis and machine intelligence, 41
  (2018), pp.~1979--1993.

\bibitem{Molchanov2020GreedyPS}
{\sc D.~Molchanov, A.~Lyzhov, Y.~Molchanova, A.~Ashukha, and D.~P. Vetrov},
  {\em Greedy policy search: A simple baseline for learnable test-time
  augmentation}, ArXiv, abs/2002.09103 (2020).

\bibitem{Morcos2019OneTT}
{\sc A.~S. Morcos, H.~Yu, M.~Paganini, and Y.~Tian}, {\em One ticket to win
  them all: generalizing lottery ticket initializations across datasets and
  optimizers}, in NeurIPS, 2019.

\bibitem{DBLP:journals/corr/abs-1906-02629}
{\sc R.~M{\"{u}}ller, S.~Kornblith, and G.~E. Hinton}, {\em When does label
  smoothing help?}, CoRR, abs/1906.02629 (2019).

\bibitem{Mundt2020AWV}
{\sc M.~Mundt, Y.~W. Hong, I.~Pliushch, and V.~Ramesh}, {\em A wholistic view
  of continual learning with deep neural networks: Forgotten lessons and the
  bridge to active and open world learning}, ArXiv, abs/2009.01797 (2020).

\bibitem{munkhdalai2017meta}
{\sc T.~Munkhdalai and H.~Yu}, {\em Meta networks}, in Proceedings of the 34th
  International Conference on Machine Learning-Volume 70, JMLR. org, 2017,
  pp.~2554--2563.

\bibitem{Nado2020EvaluatingPB}
{\sc Z.~Nado, S.~Padhy, D.~Sculley, A.~D'Amour, B.~Lakshminarayanan, and
  J.~Snoek}, {\em Evaluating prediction-time batch normalization for robustness
  under covariate shift}, ArXiv, abs/2006.10963 (2020).

\bibitem{Nakkiran2020DeepDD}
{\sc P.~Nakkiran, G.~Kaplun, Y.~Bansal, T.~Yang, B.~Barak, and I.~Sutskever},
  {\em Deep double descent: Where bigger models and more data hurt}, ArXiv,
  abs/1912.02292 (2020).

\bibitem{DBLP:journals/corr/NguyenYC14}
{\sc A.~M. Nguyen, J.~Yosinski, and J.~Clune}, {\em Deep neural networks are
  easily fooled: High confidence predictions for unrecognizable images}, CoRR,
  abs/1412.1897 (2014).

\bibitem{Nikolenko2019SyntheticDF}
{\sc S.~I. Nikolenko}, {\em Synthetic data for deep learning}, ArXiv,
  abs/1909.11512 (2019).

\bibitem{Ovadia2019CanYT}
{\sc Y.~Ovadia, E.~Fertig, J.~Ren, Z.~Nado, D.~Sculley, S.~Nowozin, J.~V.
  Dillon, B.~Lakshminarayanan, and J.~Snoek}, {\em Can you trust your model's
  uncertainty? evaluating predictive uncertainty under dataset shift}, in
  NeurIPS, 2019.

\bibitem{papernot2018deep}
{\sc N.~Papernot and P.~McDaniel}, {\em Deep k-nearest neighbors: Towards
  confident, interpretable and robust deep learning}, arXiv preprint
  arXiv:1803.04765,  (2018).

\bibitem{papineni2002bleu}
{\sc K.~Papineni, S.~Roukos, T.~Ward, and W.-J. Zhu}, {\em Bleu: a method for
  automatic evaluation of machine translation}, in Proceedings of the 40th
  annual meeting of the Association for Computational Linguistics, 2002,
  pp.~311--318.

\bibitem{DBLP:journals/corr/abs-1802-07569}
{\sc G.~I. Parisi, R.~Kemker, J.~L. Part, C.~Kanan, and S.~Wermter}, {\em
  Continual lifelong learning with neural networks: {A} review}, CoRR,
  abs/1802.07569 (2018).

\bibitem{DBLP:journals/corr/abs-1802-01528}
{\sc T.~Parr and J.~Howard}, {\em The matrix calculus you need for deep
  learning}, CoRR, abs/1802.01528 (2018).

\bibitem{Paullada2020DataAI}
{\sc A.~Paullada, I.~D. Raji, E.~M. Bender, E.~L. Denton, and A.~Hanna}, {\em
  Data and its (dis)contents: A survey of dataset development and use in
  machine learning research}, ArXiv, abs/2012.05345 (2020).

\bibitem{pereyra2017regularizing}
{\sc G.~Pereyra, G.~Tucker, J.~Chorowski, {\L}.~Kaiser, and G.~Hinton}, {\em
  Regularizing neural networks by penalizing confident output distributions},
  arXiv preprint arXiv:1701.06548,  (2017).

\bibitem{DBLP:journals/corr/PereyraTCKH17}
{\sc G.~Pereyra, G.~Tucker, J.~Chorowski, L.~Kaiser, and G.~E. Hinton}, {\em
  Regularizing neural networks by penalizing confident output distributions},
  CoRR, abs/1701.06548 (2017).

\bibitem{Picard2021Torchmanual}
{\sc D.~Picard}, {\em Torch.manual\_seed(3407) is all you need: On the
  influence of random seeds in deep learning architectures for computer
  vision}, ArXiv, abs/2109.08203 (2021).

\bibitem{power2021grokking}
{\sc A.~Power, Y.~Burda, H.~Edwards, I.~Babuschkin, and V.~Misra}, {\em
  Grokking: Generalization beyond overfit-ting on small algorithmic datasets},
  in ICLR MATH-AI Workshop, 2021.

\bibitem{Qi2020DeepIL}
{\sc H.~Qi, C.~You, X.~Wang, Y.~Ma, and J.~Malik}, {\em Deep isometric learning
  for visual recognition}, ArXiv, abs/2006.16992 (2020).

\bibitem{qian1999momentum}
{\sc N.~Qian}, {\em On the momentum term in gradient descent learning
  algorithms}, Neural networks, 12 (1999), pp.~145--151.

\bibitem{Radford2015UnsupervisedRL}
{\sc A.~Radford, L.~Metz, and S.~Chintala}, {\em Unsupervised representation
  learning with deep convolutional generative adversarial networks}, CoRR,
  abs/1511.06434 (2015).

\bibitem{Radford2016UnsupervisedRL}
\leavevmode\vrule height 2pt depth -1.6pt width 23pt, {\em Unsupervised
  representation learning with deep convolutional generative adversarial
  networks}, CoRR, abs/1511.06434 (2016).

\bibitem{Radosavovic2020DesigningND}
{\sc I.~Radosavovic, R.~P. Kosaraju, R.~B. Girshick, K.~He, and P.~Doll{\'a}r},
  {\em Designing network design spaces}, 2020 IEEE/CVF Conference on Computer
  Vision and Pattern Recognition (CVPR),  (2020), pp.~10425--10433.

\bibitem{Rae2020CompressiveTF}
{\sc J.~W. Rae, A.~Potapenko, S.~M. Jayakumar, and T.~P. Lillicrap}, {\em
  Compressive transformers for long-range sequence modelling}, ArXiv,
  abs/1911.05507 (2020).

\bibitem{Rahaman2019OnTS}
{\sc N.~Rahaman, A.~Baratin, D.~Arpit, F.~Dr{\"a}xler, M.~Lin, F.~A. Hamprecht,
  Y.~Bengio, and A.~C. Courville}, {\em On the spectral bias of neural
  networks}, in ICML, 2019.

\bibitem{rawal2020synthetic}
{\sc A.~Rawal, J.~Lehman, F.~P. Such, J.~Clune, and K.~O. Stanley}, {\em
  Synthetic petri dish: A novel surrogate model for rapid architecture search},
  arXiv preprint arXiv:2005.13092,  (2020).

\bibitem{reddi2019convergence}
{\sc S.~J. Reddi, S.~Kale, and S.~Kumar}, {\em On the convergence of adam and
  beyond}, arXiv preprint arXiv:1904.09237,  (2019).

\bibitem{DBLP:journals/corr/RedmonDGF15}
{\sc J.~Redmon, S.~K. Divvala, R.~B. Girshick, and A.~Farhadi}, {\em You only
  look once: Unified, real-time object detection}, CoRR, abs/1506.02640 (2015).

\bibitem{Reed2020EvaluatingSP}
{\sc C.~Reed, S.~Metzger, A.~Srinivas, T.~Darrell, and K.~Keutzer}, {\em
  Evaluating self-supervised pretraining without using labels}, 2020.

\bibitem{reed2014training}
{\sc S.~Reed, H.~Lee, D.~Anguelov, C.~Szegedy, D.~Erhan, and A.~Rabinovich},
  {\em Training deep neural networks on noisy labels with bootstrapping}, arXiv
  preprint arXiv:1412.6596,  (2014).

\bibitem{DBLP:journals/corr/RenHG015}
{\sc S.~Ren, K.~He, R.~B. Girshick, and J.~Sun}, {\em Faster {R-CNN:} towards
  real-time object detection with region proposal networks}, CoRR,
  abs/1506.01497 (2015).

\bibitem{Renda2020ComparingRA}
{\sc A.~Renda, J.~Frankle, and M.~Carbin}, {\em Comparing rewinding and
  fine-tuning in neural network pruning}, ArXiv, abs/2003.02389 (2020).

\bibitem{DBLP:journals/corr/Ruder17a}
{\sc S.~Ruder}, {\em An overview of multi-task learning in deep neural
  networks}, CoRR, abs/1706.05098 (2017).

\bibitem{ruder2019latent}
{\sc S.~Ruder, J.~Bingel, I.~Augenstein, and A.~S{\o}gaard}, {\em Latent
  multi-task architecture learning}, in Proceedings of the AAAI Conference on
  Artificial Intelligence, vol.~33, 2019, pp.~4822--4829.

\bibitem{ruderman2018learned}
{\sc A.~Ruderman, N.~Rabinowitz, A.~S. Morcos, and D.~Zoran}, {\em Learned
  deformation stability in convolutional neural networks}, arXiv preprint
  arXiv:1804.04438,  (2018).

\bibitem{rumelhart1988learning}
{\sc D.~E. Rumelhart, G.~E. Hinton, R.~J. Williams, et~al.}, {\em Learning
  representations by back-propagating errors}, Cognitive modeling, 5 (1988),
  p.~1.

\bibitem{DBLP:journals/corr/abs-2103-05180}
{\sc L.~Ruthotto and E.~Haber}, {\em An introduction to deep generative
  modeling}, CoRR, abs/2103.05180 (2021).

\bibitem{DBLP:journals/corr/abs-1710-09829}
{\sc S.~Sabour, N.~Frosst, and G.~E. Hinton}, {\em Dynamic routing between
  capsules}, CoRR, abs/1710.09829 (2017).

\bibitem{salimans2016weight}
{\sc T.~Salimans and D.~P. Kingma}, {\em Weight normalization: A simple
  reparameterization to accelerate training of deep neural networks}, in
  Advances in Neural Information Processing Systems, 2016, pp.~901--909.

\bibitem{samuel1962artificial}
{\sc A.~L. Samuel}, {\em Artificial intelligence: a frontier of automation},
  The Annals of the American Academy of Political and Social Science, 340
  (1962), pp.~10--20.

\bibitem{santoro2016meta}
{\sc A.~Santoro, S.~Bartunov, M.~Botvinick, D.~Wierstra, and T.~Lillicrap},
  {\em Meta-learning with memory-augmented neural networks}, in International
  conference on machine learning, 2016, pp.~1842--1850.

\bibitem{Santurkar2018HowDB}
{\sc S.~Santurkar, D.~Tsipras, A.~Ilyas, and A.~Madry}, {\em How does batch
  normalization help optimization?}, in NeurIPS, 2018.

\bibitem{Saxe2013ExactST}
{\sc A.~M. Saxe, J.~L. McClelland, and S.~Ganguli}, {\em Exact solutions to the
  nonlinear dynamics of learning in deep linear neural networks}, CoRR,
  abs/1312.6120 (2013).

\bibitem{schmidhuber1992learning}
{\sc J.~Schmidhuber}, {\em Learning factorial codes by predictability
  minimization}, Neural computation, 4 (1992), pp.~863--879.

\bibitem{DBLP:journals/corr/SchroffKP15}
{\sc F.~Schroff, D.~Kalenichenko, and J.~Philbin}, {\em Facenet: {A} unified
  embedding for face recognition and clustering}, CoRR, abs/1503.03832 (2015).

\bibitem{DBLP:journals/corr/SelvarajuDVCPB16}
{\sc R.~R. Selvaraju, A.~Das, R.~Vedantam, M.~Cogswell, D.~Parikh, and
  D.~Batra}, {\em Grad-cam: Why did you say that? visual explanations from deep
  networks via gradient-based localization}, CoRR, abs/1610.02391 (2016).

\bibitem{sennrich2015improving}
{\sc R.~Sennrich, B.~Haddow, and A.~Birch}, {\em Improving neural machine
  translation models with monolingual data}, arXiv preprint arXiv:1511.06709,
  (2015).

\bibitem{shannon1948mathematical}
{\sc C.~E. Shannon}, {\em A mathematical theory of communication}, The Bell
  system technical journal, 27 (1948), pp.~379--423.

\bibitem{shazeer2017outrageously}
{\sc N.~Shazeer, A.~Mirhoseini, K.~Maziarz, A.~Davis, Q.~Le, G.~Hinton, and
  J.~Dean}, {\em Outrageously large neural networks: The sparsely-gated
  mixture-of-experts layer}, arXiv preprint arXiv:1701.06538,  (2017).

\bibitem{Shi2020RunAF}
{\sc H.~Shi, D.~Luo, S.~Tang, J.~Wang, and Y.~Zhuang}, {\em Run away from your
  teacher: Understanding byol by a novel self-supervised approach}, ArXiv,
  abs/2011.10944 (2020).

\bibitem{shrivastava2017learning}
{\sc A.~Shrivastava, T.~Pfister, O.~Tuzel, J.~Susskind, W.~Wang, and R.~Webb},
  {\em Learning from simulated and unsupervised images through adversarial
  training}, in Proceedings of the IEEE conference on computer vision and
  pattern recognition, 2017, pp.~2107--2116.

\bibitem{simonyan2014very}
{\sc K.~Simonyan and A.~Zisserman}, {\em Very deep convolutional networks for
  large-scale image recognition}, arXiv preprint arXiv:1409.1556,  (2014).

\bibitem{DBLP:journals/corr/abs-2105-14859}
{\sc S.~Sinha and A.~B. Dieng}, {\em Consistency regularization for variational
  auto-encoders}, CoRR, abs/2105.14859 (2021).

\bibitem{smith2017cyclical}
{\sc L.~N. Smith}, {\em Cyclical learning rates for training neural networks},
  in Applications of Computer Vision (WACV), 2017 IEEE Winter Conference on,
  IEEE, 2017, pp.~464--472.

\bibitem{DBLP:journals/corr/abs-1803-09820}
{\sc L.~N. Smith}, {\em A disciplined approach to neural network
  hyper-parameters: Part 1 - learning rate, batch size, momentum, and weight
  decay}, CoRR, abs/1803.09820 (2018).

\bibitem{smith2018disciplined}
{\sc L.~N. Smith}, {\em A disciplined approach to neural network
  hyper-parameters: Part 1--learning rate, batch size, momentum, and weight
  decay}, arXiv preprint arXiv:1803.09820,  (2018).

\bibitem{smith2017don}
{\sc S.~L. Smith, P.-J. Kindermans, and Q.~V. Le}, {\em Don't decay the
  learning rate, increase the batch size}, arXiv preprint arXiv:1711.00489,
  (2017).

\bibitem{snell2017prototypical}
{\sc J.~Snell, K.~Swersky, and R.~Zemel}, {\em Prototypical networks for
  few-shot learning}, in Advances in neural information processing systems,
  2017, pp.~4077--4087.

\bibitem{sogaard2016deep}
{\sc A.~S{\o}gaard and Y.~Goldberg}, {\em Deep multi-task learning with low
  level tasks supervised at lower layers}, in Proceedings of the 54th Annual
  Meeting of the Association for Computational Linguistics (Volume 2: Short
  Papers), 2016, pp.~231--235.

\bibitem{Sommer2020TowardsPV}
{\sc D.~M. Sommer, L.~Song, S.~Wagh, and P.~Mittal}, {\em Towards probabilistic
  verification of machine unlearning}, ArXiv, abs/2003.04247 (2020).

\bibitem{springenberg2014striving}
{\sc J.~T. Springenberg, A.~Dosovitskiy, T.~Brox, and M.~Riedmiller}, {\em
  Striving for simplicity: The all convolutional net}, arXiv preprint
  arXiv:1412.6806,  (2014).

\bibitem{JMLR:v15:srivastava14a}
{\sc N.~Srivastava, G.~Hinton, A.~Krizhevsky, I.~Sutskever, and
  R.~Salakhutdinov}, {\em Dropout: A simple way to prevent neural networks from
  overfitting}, Journal of Machine Learning Research, 15 (2014),
  pp.~1929--1958.

\bibitem{standley2019tasks}
{\sc T.~Standley, A.~R. Zamir, D.~Chen, L.~Guibas, J.~Malik, and S.~Savarese},
  {\em Which tasks should be learned together in multi-task learning?}, arXiv
  preprint arXiv:1905.07553,  (2019).

\bibitem{DBLP:journals/corr/abs-1904-03011}
{\sc G.~Strezoski, N.~van Noord, and M.~Worring}, {\em Learning task
  relatedness in multi-task learning for images in context}, CoRR,
  abs/1904.03011 (2019).

\bibitem{student1908probable}
{\sc Student}, {\em The probable error of a mean}, Biometrika,  (1908),
  pp.~1--25.

\bibitem{DBLP:journals/corr/SutskeverVL14}
{\sc I.~Sutskever, O.~Vinyals, and Q.~V. Le}, {\em Sequence to sequence
  learning with neural networks}, CoRR, abs/1409.3215 (2014).

\bibitem{szegedy2016rethinking}
{\sc C.~Szegedy, V.~Vanhoucke, S.~Ioffe, J.~Shlens, and Z.~Wojna}, {\em
  Rethinking the inception architecture for computer vision}, in Proceedings of
  the IEEE conference on computer vision and pattern recognition, 2016,
  pp.~2818--2826.

\bibitem{Szegedy2014IntriguingPO}
{\sc C.~Szegedy, W.~Zaremba, I.~Sutskever, J.~Bruna, D.~Erhan, I.~J.
  Goodfellow, and R.~Fergus}, {\em Intriguing properties of neural networks},
  CoRR, abs/1312.6199 (2014).

\bibitem{Tanaka2020PruningNN}
{\sc H.~Tanaka, D.~Kunin, D.~L.~K. Yamins, and S.~Ganguli}, {\em Pruning neural
  networks without any data by iteratively conserving synaptic flow}, ArXiv,
  abs/2006.05467 (2020).

\bibitem{tangcontrol}
{\sc Y.~Tang, C.~Huang, D.~Kastelman, and J.~Bauman}, {\em Control using
  predictions as covariates in switchback experiments}.

\bibitem{Tay2020EfficientTA}
{\sc Y.~Tay, M.~Dehghani, D.~Bahri, and D.~Metzler}, {\em Efficient
  transformers: A survey}, ArXiv, abs/2009.06732 (2020).

\bibitem{Touvron2021ResMLPFN}
{\sc H.~Touvron, P.~Bojanowski, M.~Caron, M.~Cord, A.~El-Nouby, E.~Grave,
  A.~Joulin, G.~Synnaeve, J.~Verbeek, and H.~J'egou}, {\em Resmlp: Feedforward
  networks for image classification with data-efficient training}, ArXiv,
  abs/2105.03404 (2021).

\bibitem{tran2017bayesian}
{\sc T.~Tran, T.~Pham, G.~Carneiro, L.~Palmer, and I.~Reid}, {\em A bayesian
  data augmentation approach for learning deep models}, in Advances in neural
  information processing systems, 2017, pp.~2797--2806.

\bibitem{DBLP:journals/corr/VaswaniSPUJGKP17}
{\sc A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  L.~Kaiser, and I.~Polosukhin}, {\em Attention is all you need}, CoRR,
  abs/1706.03762 (2017).

\bibitem{DBLP:journals/corr/VeitWB16}
{\sc A.~Veit, M.~J. Wilber, and S.~J. Belongie}, {\em Residual networks are
  exponential ensembles of relatively shallow networks}, CoRR, abs/1605.06431
  (2016).

\bibitem{DBLP:journals/corr/abs-1712-04741}
{\sc R.~Vidal, J.~Bruna, R.~Giryes, and S.~Soatto}, {\em Mathematics of deep
  learning}, CoRR, abs/1712.04741 (2017).

\bibitem{Vig2020BERTologyMB}
{\sc J.~Vig, A.~Madani, L.~R. Varshney, C.~Xiong, R.~Socher, and N.~F. Rajani},
  {\em Bertology meets biology: Interpreting attention in protein language
  models}, bioRxiv,  (2020).

\bibitem{Vinyals2015PointerN}
{\sc O.~Vinyals, M.~Fortunato, and N.~Jaitly}, {\em Pointer networks}, ArXiv,
  abs/1506.03134 (2015).

\bibitem{wan2013regularization}
{\sc L.~Wan, M.~Zeiler, S.~Zhang, Y.~Le~Cun, and R.~Fergus}, {\em
  Regularization of neural networks using dropconnect}, in International
  conference on machine learning, PMLR, 2013, pp.~1058--1066.

\bibitem{Wang2020BayesianOF}
{\sc L.~Wang, F.~Dernoncourt, and T.~Bui}, {\em Bayesian optimization for
  selecting efficient machine learning models}, ArXiv, abs/2008.00386 (2020).

\bibitem{Wang2020KnowledgeDA}
{\sc L.~Wang and K.-J. Yoon}, {\em Knowledge distillation and student-teacher
  learning for visual intelligence: A review and new outlooks}, ArXiv,
  abs/2004.05937 (2020).

\bibitem{DBLP:journals/corr/abs-1711-07971}
{\sc X.~Wang, R.~B. Girshick, A.~Gupta, and K.~He}, {\em Non-local neural
  networks}, CoRR, abs/1711.07971 (2017).

\bibitem{weng2018attention}
{\sc L.~Weng}, {\em Attention? attention!}, lilianweng.github.io/lil-log,
  (2018).

\bibitem{wilson2003general}
{\sc D.~R. Wilson and T.~R. Martinez}, {\em The general inefficiency of batch
  training for gradient descent learning}, Neural Networks, 16 (2003),
  pp.~1429--1451.

\bibitem{wolpert1997no}
{\sc D.~H. Wolpert, W.~G. Macready, et~al.}, {\em No free lunch theorems for
  optimization}, IEEE transactions on evolutionary computation, 1 (1997),
  pp.~67--82.

\bibitem{Wortsman2020SupermasksIS}
{\sc M.~Wortsman, V.~Ramanujan, R.~Liu, A.~Kembhavi, M.~Rastegari, J.~Yosinski,
  and A.~Farhadi}, {\em Supermasks in superposition}, ArXiv, abs/2006.14769
  (2020).

\bibitem{DBLP:journals/corr/abs-1803-08494}
{\sc Y.~Wu and K.~He}, {\em Group normalization}, CoRR, abs/1803.08494 (2018).

\bibitem{Wu2021RethinkingI}
{\sc Y.~Wu and J.~Johnson}, {\em Rethinking "batch" in batchnorm}, ArXiv,
  abs/2105.07576 (2021).

\bibitem{DBLP:journals/corr/abs-2105-07576}
\leavevmode\vrule height 2pt depth -1.6pt width 23pt, {\em Rethinking "batch"
  in batchnorm}, CoRR, abs/2105.07576 (2021).

\bibitem{DBLP:journals/corr/abs-1901-00596}
{\sc Z.~Wu, S.~Pan, F.~Chen, G.~Long, C.~Zhang, and P.~S. Yu}, {\em A
  comprehensive survey on graph neural networks}, CoRR, abs/1901.00596 (2019).

\bibitem{xie2016disturblabel}
{\sc L.~Xie, J.~Wang, Z.~Wei, M.~Wang, and Q.~Tian}, {\em Disturblabel:
  Regularizing cnn on the loss layer}, in Proceedings of the IEEE Conference on
  Computer Vision and Pattern Recognition, 2016, pp.~4753--4762.

\bibitem{xie2019unsupervised}
{\sc Q.~Xie, Z.~Dai, E.~Hovy, M.-T. Luong, and Q.~V. Le}, {\em Unsupervised
  data augmentation}, arXiv preprint arXiv:1904.12848,  (2019).

\bibitem{xie2017aggregated}
{\sc S.~Xie, R.~Girshick, P.~Doll{\'a}r, Z.~Tu, and K.~He}, {\em Aggregated
  residual transformations for deep neural networks}, in Proceedings of the
  IEEE conference on computer vision and pattern recognition, 2017,
  pp.~1492--1500.

\bibitem{DBLP:journals/corr/XuBKCCSZB15}
{\sc K.~Xu, J.~Ba, R.~Kiros, K.~Cho, A.~C. Courville, R.~Salakhutdinov, R.~S.
  Zemel, and Y.~Bengio}, {\em Show, attend and tell: Neural image caption
  generation with visual attention}, CoRR, abs/1502.03044 (2015).

\bibitem{DBLP:journals/corr/YangH16}
{\sc Y.~Yang and T.~M. Hospedales}, {\em Deep multi-task representation
  learning: {A} tensor factorisation approach}, CoRR, abs/1605.06391 (2016).

\bibitem{DBLP:journals/corr/YaoCVDD15}
{\sc K.~Yao, T.~Cohn, K.~Vylomova, K.~Duh, and C.~Dyer}, {\em Depth-gated
  {LSTM}}, CoRR, abs/1508.03790 (2015).

\bibitem{You2020DrawingET}
{\sc H.~You, C.~Li, P.~Xu, Y.~Fu, Y.~Wang, X.~Chen, Y.~Lin, Z.~Wang, and
  R.~Baraniuk}, {\em Drawing early-bird tickets: Towards more efficient
  training of deep networks}, ArXiv, abs/1909.11957 (2020).

\bibitem{Yu2020PlayingTL}
{\sc H.~Yu, S.~Edunov, Y.~Tian, and A.~S. Morcos}, {\em Playing the lottery
  with rewards and multiple languages: lottery tickets in rl and nlp}, ArXiv,
  abs/1906.02768 (2020).

\bibitem{yun2019cutmix}
{\sc S.~Yun, D.~Han, S.~J. Oh, S.~Chun, J.~Choe, and Y.~Yoo}, {\em Cutmix:
  Regularization strategy to train strong classifiers with localizable
  features}, arXiv preprint arXiv:1905.04899,  (2019).

\bibitem{Zbontar2021BarlowTS}
{\sc J.~Zbontar, L.~Jing, I.~Misra, Y.~LeCun, and S.~Deny}, {\em Barlow twins:
  Self-supervised learning via redundancy reduction}, ArXiv, abs/2103.03230
  (2021).

\bibitem{zeiler2012adadelta}
{\sc M.~D. Zeiler}, {\em Adadelta: an adaptive learning rate method}, arXiv
  preprint arXiv:1212.5701,  (2012).

\bibitem{DBLP:journals/corr/ZeilerF13}
{\sc M.~D. Zeiler and R.~Fergus}, {\em Visualizing and understanding
  convolutional networks}, CoRR, abs/1311.2901 (2013).

\bibitem{zhang2017mixup}
{\sc H.~Zhang, M.~Cisse, Y.~N. Dauphin, and D.~Lopez-Paz}, {\em mixup: Beyond
  empirical risk minimization}, arXiv preprint arXiv:1710.09412,  (2017).

\bibitem{zhang2019fixup}
{\sc H.~Zhang, Y.~N. Dauphin, and T.~Ma}, {\em Fixup initialization: Residual
  learning without normalization}, arXiv preprint arXiv:1901.09321,  (2019).

\bibitem{Zhang2019SelfAttentionGA}
{\sc H.~Zhang, I.~J. Goodfellow, D.~N. Metaxas, and A.~Odena}, {\em
  Self-attention generative adversarial networks}, ArXiv, abs/1805.08318
  (2019).

\bibitem{DBLP:journals/corr/ZhangY17aa}
{\sc Y.~Zhang and Q.~Yang}, {\em A survey on multi-task learning}, CoRR,
  abs/1707.08114 (2017).

\bibitem{zhao2019recommending}
{\sc Z.~Zhao, L.~Hong, L.~Wei, J.~Chen, A.~Nath, S.~Andrews, A.~Kumthekar,
  M.~Sathiamoorthy, X.~Yi, and E.~Chi}, {\em Recommending what video to watch
  next: a multitask ranking system}, in Proceedings of the 13th ACM Conference
  on Recommender Systems, 2019, pp.~43--51.

\bibitem{DBLP:journals/corr/abs-1905-01067}
{\sc H.~Zhou, J.~Lan, R.~Liu, and J.~Yosinski}, {\em Deconstructing lottery
  tickets: Zeros, signs, and the supermask}, CoRR, abs/1905.01067 (2019).

\bibitem{DBLP:journals/corr/ZhuPIE17}
{\sc J.~Zhu, T.~Park, P.~Isola, and A.~A. Efros}, {\em Unpaired image-to-image
  translation using cycle-consistent adversarial networks}, CoRR,
  abs/1703.10593 (2017).

\bibitem{zoph2019learning}
{\sc B.~Zoph, E.~D. Cubuk, G.~Ghiasi, T.-Y. Lin, J.~Shlens, and Q.~V. Le}, {\em
  Learning data augmentation strategies for object detection}, arXiv preprint
  arXiv:1906.11172,  (2019).

\end{thebibliography}
