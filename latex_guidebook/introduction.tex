\chapter{Introduction}

But if you teach your computer to fish..


\section{Motivation for this text}
There are many great resources that exist.

I wanted to create the guide I wish I found.

\r{ML -- study of how programs learn from data. predictive analytics or statistical learning.}


\section{What}

\r{data and objective. ML tries to ``model'' the data as ``best'' as possible -- where the model may mean any number of things (I'll define the model as representing ``some function'' that accepts inputs and produces outputs throughout this text) and where ``best'' is user defined, typically as some quantitative value/measure. Typically, the goal is produce a model/function for data that is as generalizable as possible -- one that is capable of ``performing'' well, in the future based on some predefined objective on data the model has never seen before.}

% TODO: lot to unpack here -- maybe a highlighting scheme would be better than the quotes for user defined concepts

\r{as you may imagine, there are many other constraints that may be placed on this model. Maybe it needs to be able to ``infer'' a certain number of samples per unit time. Maybe the model must be able to execute in a resource constraint environment (where the constrained resource could be battery life, memory, etc.).}

% TODO: more


\subsection{Rule based vs ``learning''}


\subsection{High Level Overview}


\r{Arthur Samuel, essay ``Artificial Intelligence: A frontier of automation'' \cite{samuel1962artificial} -- ``ML is the study that gives computers the ability to learn without being explicitly programed.'' }

\r{Tom Mitchel -- ``A program can be said to learn from experience `E' with respect to some class of tasks `T' and performance measure `P', if its performance at tasks in `T', as measured by `P', improves with experience `E'.''}

\r{ML is everywhere.... everyday --- personalized music, show,book,product recommendations, automatic image tagging to specific tasks, detecting fraudulent credit card activity -- analyzing medical images (benign, or malignant). }

\TD{TODO: venn diagram, AI (knowledge bases -- logical inference rules (cyc))-> Machine Learning  (SVM, Logistic Regression, naive bayes) -> Representation Learning (...), Deep Learning (MLP, Deep CNN, RNN)}



\subsection{Deep Learning}

\r{Model depth --- depends on the definition of what is considered a computational step --- what level of detail is being considered. This may be either the length of the longest path through the computational graph, where each multiplication, addition, etc. are considered, or this may be described by how the concepts are related to one another, where a group of opperations may be grouped together for a single count (such as in a dense or convolutional layer). In general, we will not be overly concerned with depth or how it is described. It is only important to be aware that some individuals may have different definitions for ``deep'' than others.}

\subsubsection{Why Now?}

\r{Why is deep learning suddenly so popular?}

\r{Deep learning is nothing ``new''. It has been rebranded, i.e. gone by many different names \TD{cybernetics (1940s-1950s), connectionism (1980s-1990s), deep learning ($\approx 2006$) more prev+new examples} and its popularity has increased and decreased over time.}

\TD{``Deep Learning = new electricity'' - Ng}

\r{A few reasons that may be contributed to the recent surge in popularity may be the following:}

\begin{itemize}
	
	\item \textit{Data (a lot more of it)}: \r{increase in the collection and labeling of data} \TD{information about the increase in the collection of data}.
	
	\item \textit{Hardware (Computational Power/Price)}: \r{GPUs, TPUs, examples of price -- both clock freq, number cores, memory, bandwidth}.
	
	\item \textit{Performance Benchmarks (Kaggle challenges, etc.)}: \r{Examples like imagenet}.
	
	\item \textit{Software (algorithms)}: \r{Advances in activation functions, weight-initialization schemes, optimization schemes --- batchnormalization, residual connections, separable convolutions --- allowed for deeper models to be trained.}
	
	\item \textit{Software (Libraries)}: \r{More accessible --previously needed to have a deep understanding of C++ and/or CUDA --- python --- pytorch, theano, tensorflow, abstractions on top, lasagne, keras}. \textcolor{green}{TODO: CITE these}
	
	\item \textit{Investment}: \r{Rapid rise of machine learning investment and deployment}
	
\end{itemize}

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.5\textwidth]{example-image-a}\hfil
	\caption{Cyclic figure of software, hardware, investment, benchmarks, \textcolor{green}{TODO}}
	\label{fig:cyclic_rise_of_dl_overview}
\end{figure}
\TD{TODO: figure of how software, hardware, investment, benchmarks are related to the rise of ML .}

\section{Why ML}

%TODO: is this the right location for this



\section{Notes}

\subsection{Target Audience}

\r{The target audience for this book is not well defined, largely because I am writing this collection of notes and guides for myself. However, as I continue to iterate on the ideas, I hope to make them easier to understand. The intention is to one day have a large enough collection to call a ``book'' and to publish for a larger audience.}

\subsection{How to Read this Book}
\r{Excepts sequential acess, but attempts to support semi-random access as well.}

\TD{``All models are wrong, but some are useful''. George E. P. Box}

\TD{TODO: figure of the structure of the book. I really like figure 1.6 in DL}


