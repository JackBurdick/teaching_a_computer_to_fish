%% techniques
\chapter{Augmentation Techniques}
\label{app_aug_techniques}

\r{Including Imagery}

\r{flip, rotate. color/channel manipulation}

\r{mixup\cite{zhang2017mixup}}

\r{cutout\cite{devries2017improved}}

\r{cutmix\cite{yun2019cutmix}}

\TD{language -- back translation\cite{sennrich2015improving}}

% TODO: blog about this: https://ai.googleblog.com/2019/07/advancing-semi-supervised-learning-with.html
\TD{unsupervised augmentation\cite{xie2019unsupervised}}

%% learning augmentation

% TODO: not sure this belongs here
\r{Sample Pairing\cite{inoue2018data}}

\r{Smart Augmentation\cite{lemley2017smart}}

\r{GAN\cite{shrivastava2017learning}}

\r{population based augmentation (PBA)\cite{ho2019population}}

\r{Bayesian data augmentation\cite{tran2017bayesian}}

\TD{distortions, patches, jigsaw, color}

\TD{AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty \cite{Hendrycks2020AugMixAS}}

% image augmentation
\TD{Attacks Which Do Not Kill Training Make Adversarial Learning Stronger \cite{DBLP:journals/corr/abs-2002-11242}}

\TD{DuBIN --- AugMax: Adversarial Composition of Random Augmentations for Robust Training \cite{Wang2021AugMaxAC}}

% similar to dropout?
\TD{Random Erasing Data Augmentation \cite{DBLP:journals/corr/abs-1708-04896}}

%% autoaugment

\r{AutoAugment\cite{cubuk2018autoaugment}}

\r{Comment that AutoAugment can be applied directly to a dataset as well as transfer the learned policies to new datasets.}

\TD{figure of loop. controller, strategy, child network, update controller}

\r{Fast AutoAugment\cite{lim2019fast} improves upon the original search strategy in the original AutoAugment paper.}

\r{Unsupervised Augmentation}

\TD{autoaugment for object detection \cite{zoph2019learning}}

\section{Data Imbalance or Unbalanced Data}
\label{app_data_imbalance}

% TODO: special case of augmentation??

\TD{A Survey of Predictive Modelling under Imbalanced Distributions \cite{DBLP:journals/corr/BrancoTR15}}

\TD{\cite{krawczyk2016learning}}

\r{An ``imbalance in the data'' may have many meanings. That is, the labels could be imbalanced (e.g. in a binary classifier, there may be n times the number of instances with the label p when compared to the label q), the features may be imbalanced, (e.g. facial recognition is being performed on collected images that are composed of overwhemingly white, male, brown hair, clean shaven, hazel eye individuals), or it may mean a combination of the above.}

\r{this poses a problem, as typically the optimization process treats all samples individually and equally, which may (often does) pose problems when creating predictions on imbalanced data}

\r{Two main high level approaches to addressing this issue. You can either modify the (or utilize a combination of the listed):}
\begin{itemize}[noitemsep,topsep=0pt]
	\item data
	\item model
	\item post-processing
\end{itemize}

\r{data modification approaches aim to create a quisi-balanced representation, often through some re-sampling scheme. Simple example for would be to down-sampling the overrepresented class and upsampling the underrepresented class -- where class here might mean target variable or feature attribute.}

\r{when discussing class imbalance in reference to a continuous variable, the term skewed is often used to describe the data, whereas unbalanced or imbalanced is used for discrete variables}

\TD{relevance function --- }

\subsection{Methods}

\TD{paper to read: \TD{Self-paced Ensemble for Highly Imbalanced Massive Data Classification \cite{Liu2020SelfpacedEF}}}

\subsubsection{Data}

\r{as mentioned, under/oversampling scheme}

\TD{Method -- SMOGN}

\TD{Method --- SMOTE (\textbf{S}ynthetic \textbf{M}inority \textbf{O}versampling \textbf{T}echnique)}

\TD{method --- Tomek Links, select pairs of examples that are of opposite class, near one another. \TD{Figure}}

\TD{``shows that outcome imbalance is not a problem in itself, and that imbalance correction may even worsen model performance'' -- The harm of class imbalance corrections for risk prediction models: illustration and simulation using logistic regression~\cite{Goorbergh2022TheHO}}

\subsubsection{Model}

\TD{Utility-based Regression --- penalty based on \TD{relevance function}}

\paragraph{Losses}

% TODO: does this belong here?
% generalized loss function
\TD{Cyclical Focal Loss~\cite{Smith2022CyclicalFL}}
\TD{Asymmetric Loss For Multi-Label Classification~\cite{DBLP:journals/corr/abs-2009-14119}}

\subsubsection{Post processing}

% TODO: is this where calibration belongs??
\paragraph{Calibration}

%TODO: need to get a grasp on this...

% original
\TD{On Calibration of Modern Neural Networks \cite{DBLP:journals/corr/GuoPSW17}}

% recent
\TD{Revisiting the Calibration of Modern Neural Networks~\cite{DBLP:journals/corr/abs-2106-07998}}

% other, relevant
\TD{On the Dark Side of Calibration for Modern Neural Networks~\cite{Singh2021OnTD}}

% other, popular
\TD{Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles~\cite{Lakshminarayanan2017SimpleAS}}



\subsection{Evaluation}

\r{Difficult to discuss class imbalance without discussing the importance of having appropriate metrics in place to evaluate the methods. \TD{point to example of disease test where 1 out of N are positive --- acc is very high, yet...}}

\TD{point to metrics section and specific metrics that may be useful for various scenarios}
